{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Transformer\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import RobertaModel, AutoTokenizer, RobertaForCausalLM\n",
    "from transformers import GenerationConfig\n",
    "from transformers import RobertaConfig\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = RobertaConfig.from_pretrained(\"roberta-base\")\n",
    "model_config.is_decoder = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta = RobertaForCausalLM.from_pretrained('roberta-base', config=model_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\", padding_side = \"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,   133,  2119,  6219, 23602, 13855,    81,     5, 22414,  2335,\n",
       "             2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\")\n",
    "input_ids\n",
    "#print(input_ids)\n",
    "#roberta(input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"max_new_tokens\": 25,\n",
       "  \"min_new_tokens\": 15\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_config = GenerationConfig(min_new_tokens = 15, max_new_tokens = 25)\n",
    "gen_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=6, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = roberta\n",
    "text = \"The three colors are\"\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\")#,padding='max_length',truncation=True)#.to(\"cuda\")\n",
    "model_inputs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The three colors are'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids = model.generate(**model_inputs, generation_config=gen_config)#, do_sample = True)\n",
    "tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,  133,  130, 8089,   32,    2,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me about the french revolution...\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForCausalLM\n",
    "\n",
    "\n",
    "model = RobertaForCausalLM.from_pretrained(\"roberta-base\", is_decoder=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\", device_map=\"auto\")\n",
    "prompt = \"Tell me about the french revolution.\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "generate_ids = model.generate(inputs.input_ids.to(model.device), max_new_tokens=128, do_sample=True)\n",
    "print(tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f8b3b5f9dc4ccba099cff41e5a5677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/644 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2cc833b65343b8affd87cbb611ef22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/663M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ec6b21e6124184b802f1b3a18d4672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1c7ca46b394ca190779845b01dee1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3870820906049fd8161e6bcada5503d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f009a2b6eb30464886c41d2a25f73440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ed6b276ab04b16af46aec6a1b8e7d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me about the french revolution.\n",
      "Tell me about French socialism.\n",
      "I mean, what is it you like about french politics?\n"
     ]
    }
   ],
   "source": [
    "from transformers import OPTForCausalLM, AutoTokenizer\n",
    "\n",
    "model = OPTForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\", device_map=\"auto\")\n",
    "prompt = \"Tell me about the french revolution.\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "generate_ids = model.generate(inputs.input_ids.to(model.device), max_new_tokens=128, do_sample=True)\n",
    "print(tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>This is the first sentence. This is the second sentence.</s>\n"
     ]
    }
   ],
   "source": [
    "# instantiate sentence fusion model\n",
    "from transformers import EncoderDecoderModel, AutoTokenizer\n",
    "sentence_fuser = EncoderDecoderModel.from_pretrained(\"google/roberta2roberta_L-24_discofuse\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/roberta2roberta_L-24_discofuse\")\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    \"This is the first sentence. This is the second sentence.\", add_special_tokens=False, return_tensors=\"pt\"\n",
    ").input_ids\n",
    "\n",
    "outputs = sentence_fuser.generate(input_ids)\n",
    "\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EncoderDecoderModel, BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "#model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-cased\", \"bert-base-cased\")\n",
    "model = RobertaForCausalLM.from_pretrained(\"roberta-base\", is_decoder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapters import BnConfig, AutoAdapterModel, PromptTuningConfig\n",
    "import adapters\n",
    "from peft import PeftConfig\n",
    "\n",
    "\n",
    "adapters.init(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PromptTuningConfig(prompt_length=10)\n",
    "model.add_adapter(\"dummy\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta.embeddings.word_embeddings.weight\n",
      "roberta.embeddings.position_embeddings.weight\n",
      "roberta.embeddings.token_type_embeddings.weight\n",
      "roberta.embeddings.LayerNorm.weight\n",
      "roberta.embeddings.LayerNorm.bias\n",
      "roberta.encoder.layer.0.attention.self.query.weight\n",
      "roberta.encoder.layer.0.attention.self.query.bias\n",
      "roberta.encoder.layer.0.attention.self.key.weight\n",
      "roberta.encoder.layer.0.attention.self.key.bias\n",
      "roberta.encoder.layer.0.attention.self.value.weight\n",
      "roberta.encoder.layer.0.attention.self.value.bias\n",
      "roberta.encoder.layer.0.attention.output.dense.weight\n",
      "roberta.encoder.layer.0.attention.output.dense.bias\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.0.intermediate.dense.weight\n",
      "roberta.encoder.layer.0.intermediate.dense.bias\n",
      "roberta.encoder.layer.0.output.dense.weight\n",
      "roberta.encoder.layer.0.output.dense.bias\n",
      "roberta.encoder.layer.0.output.LayerNorm.weight\n",
      "roberta.encoder.layer.0.output.LayerNorm.bias\n",
      "roberta.encoder.layer.1.attention.self.query.weight\n",
      "roberta.encoder.layer.1.attention.self.query.bias\n",
      "roberta.encoder.layer.1.attention.self.key.weight\n",
      "roberta.encoder.layer.1.attention.self.key.bias\n",
      "roberta.encoder.layer.1.attention.self.value.weight\n",
      "roberta.encoder.layer.1.attention.self.value.bias\n",
      "roberta.encoder.layer.1.attention.output.dense.weight\n",
      "roberta.encoder.layer.1.attention.output.dense.bias\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.1.intermediate.dense.weight\n",
      "roberta.encoder.layer.1.intermediate.dense.bias\n",
      "roberta.encoder.layer.1.output.dense.weight\n",
      "roberta.encoder.layer.1.output.dense.bias\n",
      "roberta.encoder.layer.1.output.LayerNorm.weight\n",
      "roberta.encoder.layer.1.output.LayerNorm.bias\n",
      "roberta.encoder.layer.2.attention.self.query.weight\n",
      "roberta.encoder.layer.2.attention.self.query.bias\n",
      "roberta.encoder.layer.2.attention.self.key.weight\n",
      "roberta.encoder.layer.2.attention.self.key.bias\n",
      "roberta.encoder.layer.2.attention.self.value.weight\n",
      "roberta.encoder.layer.2.attention.self.value.bias\n",
      "roberta.encoder.layer.2.attention.output.dense.weight\n",
      "roberta.encoder.layer.2.attention.output.dense.bias\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.2.intermediate.dense.weight\n",
      "roberta.encoder.layer.2.intermediate.dense.bias\n",
      "roberta.encoder.layer.2.output.dense.weight\n",
      "roberta.encoder.layer.2.output.dense.bias\n",
      "roberta.encoder.layer.2.output.LayerNorm.weight\n",
      "roberta.encoder.layer.2.output.LayerNorm.bias\n",
      "roberta.encoder.layer.3.attention.self.query.weight\n",
      "roberta.encoder.layer.3.attention.self.query.bias\n",
      "roberta.encoder.layer.3.attention.self.key.weight\n",
      "roberta.encoder.layer.3.attention.self.key.bias\n",
      "roberta.encoder.layer.3.attention.self.value.weight\n",
      "roberta.encoder.layer.3.attention.self.value.bias\n",
      "roberta.encoder.layer.3.attention.output.dense.weight\n",
      "roberta.encoder.layer.3.attention.output.dense.bias\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.3.intermediate.dense.weight\n",
      "roberta.encoder.layer.3.intermediate.dense.bias\n",
      "roberta.encoder.layer.3.output.dense.weight\n",
      "roberta.encoder.layer.3.output.dense.bias\n",
      "roberta.encoder.layer.3.output.LayerNorm.weight\n",
      "roberta.encoder.layer.3.output.LayerNorm.bias\n",
      "roberta.encoder.layer.4.attention.self.query.weight\n",
      "roberta.encoder.layer.4.attention.self.query.bias\n",
      "roberta.encoder.layer.4.attention.self.key.weight\n",
      "roberta.encoder.layer.4.attention.self.key.bias\n",
      "roberta.encoder.layer.4.attention.self.value.weight\n",
      "roberta.encoder.layer.4.attention.self.value.bias\n",
      "roberta.encoder.layer.4.attention.output.dense.weight\n",
      "roberta.encoder.layer.4.attention.output.dense.bias\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.4.intermediate.dense.weight\n",
      "roberta.encoder.layer.4.intermediate.dense.bias\n",
      "roberta.encoder.layer.4.output.dense.weight\n",
      "roberta.encoder.layer.4.output.dense.bias\n",
      "roberta.encoder.layer.4.output.LayerNorm.weight\n",
      "roberta.encoder.layer.4.output.LayerNorm.bias\n",
      "roberta.encoder.layer.5.attention.self.query.weight\n",
      "roberta.encoder.layer.5.attention.self.query.bias\n",
      "roberta.encoder.layer.5.attention.self.key.weight\n",
      "roberta.encoder.layer.5.attention.self.key.bias\n",
      "roberta.encoder.layer.5.attention.self.value.weight\n",
      "roberta.encoder.layer.5.attention.self.value.bias\n",
      "roberta.encoder.layer.5.attention.output.dense.weight\n",
      "roberta.encoder.layer.5.attention.output.dense.bias\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.5.intermediate.dense.weight\n",
      "roberta.encoder.layer.5.intermediate.dense.bias\n",
      "roberta.encoder.layer.5.output.dense.weight\n",
      "roberta.encoder.layer.5.output.dense.bias\n",
      "roberta.encoder.layer.5.output.LayerNorm.weight\n",
      "roberta.encoder.layer.5.output.LayerNorm.bias\n",
      "roberta.encoder.layer.6.attention.self.query.weight\n",
      "roberta.encoder.layer.6.attention.self.query.bias\n",
      "roberta.encoder.layer.6.attention.self.key.weight\n",
      "roberta.encoder.layer.6.attention.self.key.bias\n",
      "roberta.encoder.layer.6.attention.self.value.weight\n",
      "roberta.encoder.layer.6.attention.self.value.bias\n",
      "roberta.encoder.layer.6.attention.output.dense.weight\n",
      "roberta.encoder.layer.6.attention.output.dense.bias\n",
      "roberta.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.6.intermediate.dense.weight\n",
      "roberta.encoder.layer.6.intermediate.dense.bias\n",
      "roberta.encoder.layer.6.output.dense.weight\n",
      "roberta.encoder.layer.6.output.dense.bias\n",
      "roberta.encoder.layer.6.output.LayerNorm.weight\n",
      "roberta.encoder.layer.6.output.LayerNorm.bias\n",
      "roberta.encoder.layer.7.attention.self.query.weight\n",
      "roberta.encoder.layer.7.attention.self.query.bias\n",
      "roberta.encoder.layer.7.attention.self.key.weight\n",
      "roberta.encoder.layer.7.attention.self.key.bias\n",
      "roberta.encoder.layer.7.attention.self.value.weight\n",
      "roberta.encoder.layer.7.attention.self.value.bias\n",
      "roberta.encoder.layer.7.attention.output.dense.weight\n",
      "roberta.encoder.layer.7.attention.output.dense.bias\n",
      "roberta.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.7.intermediate.dense.weight\n",
      "roberta.encoder.layer.7.intermediate.dense.bias\n",
      "roberta.encoder.layer.7.output.dense.weight\n",
      "roberta.encoder.layer.7.output.dense.bias\n",
      "roberta.encoder.layer.7.output.LayerNorm.weight\n",
      "roberta.encoder.layer.7.output.LayerNorm.bias\n",
      "roberta.encoder.layer.8.attention.self.query.weight\n",
      "roberta.encoder.layer.8.attention.self.query.bias\n",
      "roberta.encoder.layer.8.attention.self.key.weight\n",
      "roberta.encoder.layer.8.attention.self.key.bias\n",
      "roberta.encoder.layer.8.attention.self.value.weight\n",
      "roberta.encoder.layer.8.attention.self.value.bias\n",
      "roberta.encoder.layer.8.attention.output.dense.weight\n",
      "roberta.encoder.layer.8.attention.output.dense.bias\n",
      "roberta.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.8.intermediate.dense.weight\n",
      "roberta.encoder.layer.8.intermediate.dense.bias\n",
      "roberta.encoder.layer.8.output.dense.weight\n",
      "roberta.encoder.layer.8.output.dense.bias\n",
      "roberta.encoder.layer.8.output.LayerNorm.weight\n",
      "roberta.encoder.layer.8.output.LayerNorm.bias\n",
      "roberta.encoder.layer.9.attention.self.query.weight\n",
      "roberta.encoder.layer.9.attention.self.query.bias\n",
      "roberta.encoder.layer.9.attention.self.key.weight\n",
      "roberta.encoder.layer.9.attention.self.key.bias\n",
      "roberta.encoder.layer.9.attention.self.value.weight\n",
      "roberta.encoder.layer.9.attention.self.value.bias\n",
      "roberta.encoder.layer.9.attention.output.dense.weight\n",
      "roberta.encoder.layer.9.attention.output.dense.bias\n",
      "roberta.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.9.intermediate.dense.weight\n",
      "roberta.encoder.layer.9.intermediate.dense.bias\n",
      "roberta.encoder.layer.9.output.dense.weight\n",
      "roberta.encoder.layer.9.output.dense.bias\n",
      "roberta.encoder.layer.9.output.LayerNorm.weight\n",
      "roberta.encoder.layer.9.output.LayerNorm.bias\n",
      "roberta.encoder.layer.10.attention.self.query.weight\n",
      "roberta.encoder.layer.10.attention.self.query.bias\n",
      "roberta.encoder.layer.10.attention.self.key.weight\n",
      "roberta.encoder.layer.10.attention.self.key.bias\n",
      "roberta.encoder.layer.10.attention.self.value.weight\n",
      "roberta.encoder.layer.10.attention.self.value.bias\n",
      "roberta.encoder.layer.10.attention.output.dense.weight\n",
      "roberta.encoder.layer.10.attention.output.dense.bias\n",
      "roberta.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.10.intermediate.dense.weight\n",
      "roberta.encoder.layer.10.intermediate.dense.bias\n",
      "roberta.encoder.layer.10.output.dense.weight\n",
      "roberta.encoder.layer.10.output.dense.bias\n",
      "roberta.encoder.layer.10.output.LayerNorm.weight\n",
      "roberta.encoder.layer.10.output.LayerNorm.bias\n",
      "roberta.encoder.layer.11.attention.self.query.weight\n",
      "roberta.encoder.layer.11.attention.self.query.bias\n",
      "roberta.encoder.layer.11.attention.self.key.weight\n",
      "roberta.encoder.layer.11.attention.self.key.bias\n",
      "roberta.encoder.layer.11.attention.self.value.weight\n",
      "roberta.encoder.layer.11.attention.self.value.bias\n",
      "roberta.encoder.layer.11.attention.output.dense.weight\n",
      "roberta.encoder.layer.11.attention.output.dense.bias\n",
      "roberta.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.11.intermediate.dense.weight\n",
      "roberta.encoder.layer.11.intermediate.dense.bias\n",
      "roberta.encoder.layer.11.output.dense.weight\n",
      "roberta.encoder.layer.11.output.dense.bias\n",
      "roberta.encoder.layer.11.output.LayerNorm.weight\n",
      "roberta.encoder.layer.11.output.LayerNorm.bias\n",
      "roberta.prompt_tuning.prompt_tunings.dummy.prompt_embedding.weight\n",
      "lm_head.bias\n",
      "lm_head.dense.weight\n",
      "lm_head.dense.bias\n",
      "lm_head.layer_norm.weight\n",
      "lm_head.layer_norm.bias\n"
     ]
    }
   ],
   "source": [
    "for n,p in model.named_parameters():\n",
    "    print(n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTrainingArguments(output_dir='tbag', overwrite_output_dir=False, do_train=False, do_eval=False, do_predict=False, eval_strategy=<IntervalStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, eval_delay=0, torch_empty_cache_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, lr_scheduler_kwargs={}, warmup_ratio=0.0, warmup_steps=0, log_level='passive', log_level_replica='warning', log_on_each_node=True, logging_dir='tbag\\\\runs\\\\Jan15_21-24-04_DESKTOP-RMKLK7E', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=500, logging_nan_inf_filter=True, save_strategy=<SaveStrategy.STEPS: 'steps'>, save_steps=500, save_total_limit=None, save_safetensors=True, save_on_each_node=False, save_only_model=False, restore_callback_states_from_checkpoint=False, no_cuda=False, use_cpu=False, use_mps_device=False, seed=42, data_seed=None, jit_mode_eval=False, use_ipex=False, bf16=False, fp16=False, fp16_opt_level='O1', half_precision_backend='auto', bf16_full_eval=False, fp16_full_eval=False, tf32=None, local_rank=0, ddp_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=None, dataloader_num_workers=0, dataloader_prefetch_factor=None, past_index=-1, run_name='tbag', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, fsdp=[], fsdp_min_num_params=0, fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, fsdp_transformer_layer_cls_to_wrap=None, accelerator_config=AcceleratorConfig(split_batches=False, dispatch_batches=None, even_batches=True, use_seedable_sampler=True, non_blocking=False, gradient_accumulation_kwargs=None, use_configured_state=False), deepspeed=None, label_smoothing_factor=0.0, optim=<OptimizerNames.ADAMW_TORCH: 'adamw_torch'>, optim_args=None, adafactor=False, group_by_length=False, length_column_name='length', report_to=['tensorboard', 'wandb'], ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, ddp_broadcast_buffers=None, dataloader_pin_memory=True, dataloader_persistent_workers=False, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, hub_model_id=None, hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, hub_private_repo=None, hub_always_push=False, gradient_checkpointing=False, gradient_checkpointing_kwargs=None, include_inputs_for_metrics=False, include_for_metrics=[], eval_do_concat_batches=True, fp16_backend='auto', evaluation_strategy=None, push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters='', auto_find_batch_size=False, full_determinism=False, torchdynamo=None, ray_scope='last', ddp_timeout=1800, torch_compile=False, torch_compile_backend=None, torch_compile_mode=None, dispatch_batches=None, split_batches=None, include_tokens_per_second=False, include_num_input_tokens_seen=False, neftune_noise_alpha=None, optim_target_modules=None, batch_eval_metrics=False, eval_on_start=False, use_liger_kernel=False, eval_use_gather_object=False, average_tokens_across_devices=False, sortish_sampler=False, predict_with_generate=False, generation_max_length=None, generation_num_beams=None, generation_config=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "train_args = Seq2SeqTrainingArguments(output_dir=\"tbag\")\n",
    "trainer = Seq2SeqTrainer(model=model, args=train_args)\n",
    "train_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.scan_dataset import ScanDataset\n",
    "def _mk_train_dataset(e_type):\n",
    "    paths = e_type.get_data_paths()\n",
    "    max_len = self.config.emb_dim\n",
    "    device = self.device\n",
    "    train_dataset = ScanDataset(\n",
    "        dataset_path= paths[\"train\"],\n",
    "        in_seq_len=max_len,\n",
    "        out_seq_len=max_len + 20,\n",
    "        device=device,\n",
    "    )\n",
    "    return train_dataset\n",
    "\n",
    "def _mk_test_dataset():\n",
    "    # call alwyas after mk_train_dataset\n",
    "    paths = self.e_type.get_data_paths()\n",
    "    max_len = self.config.emb_dim\n",
    "    device = self.device\n",
    "    test_dataset = ScanDataset(\n",
    "        dataset_path= paths[\"test\"],\n",
    "        vocab=self.train_dataset.vocab,\n",
    "        in_seq_len=max_len,\n",
    "        out_seq_len=max_len + 20,\n",
    "        device=device,\n",
    "    ) \n",
    "    return test_dataset\n",
    "\n",
    "#   def _mk_dataloaders(self): \n",
    "\n",
    "#         train_loader = DataLoader(self.train_dataset,\n",
    "#                                 batch_size=self.config.batch_size,\n",
    "#                                 shuffle=True\n",
    "#                                 )\n",
    "#         test_loader = DataLoader(self.test_dataset,\n",
    "#                                 batch_size=self.config.batch_size_eval,\n",
    "#                                 )\n",
    "#         return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForCausalLM, BartModel\n",
    "# https://github.com/huggingface/transformers/blob/v4.48.0/src/transformers/models/bart/modeling_bart.py#L948\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "model = BartModel.from_pretrained('facebook/bart-base')\n",
    "\n",
    "inputs = tokenizer([\"Three colors: blue,\",\"turn left after jump twice\"], return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=30,padding_side='right')\n",
    "lbls = tokenizer([\"Three colors: blue, red, green\",\"I_JUMP I_JUMP I_TURN_LEFT\"], return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=30,padding_side='right')\n",
    "#outputs = model.generate(**inputs,max_new_tokens=20)\n",
    "outputs = model(**inputs)\n",
    "inputs.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartTokenizer(name_or_path='facebook/bart-base', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "upscale = torch.nn.Linear(768, tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30, 768])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_out = model.encoder(inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "enc_out[\"last_hidden_state\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30, 768])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_out = model.decoder(inputs['input_ids'], attention_mask=inputs['attention_mask'], encoder_hidden_states=enc_out[\"last_hidden_state\"])\n",
    "dec_out[\"last_hidden_state\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30, 50265])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outt = upscale(dec_out[\"last_hidden_state\"])\n",
    "outt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = outt.argmax(-1)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' baffled reservations]} redirect contextsAid Rece cafes ABVajoajoajoajoajohalhalhal cafes cafes handsomehalhalhalhal cafes cafes cafes cafes Spell cafes',\n",
       " ' baffledUnlike Chineseessim /* Dex Rece ridge Simulator containingayson GeForceayson containing containing containingayson ridge ridgeayson containing containing Malt Malt McF jur jur jurampsdoor']"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decode with tokenizer\n",
    "tokenizer.batch_decode(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "criterion = CrossEntropyLoss()#(ignore_index=self.train_dataset.vocab.pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbls['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.6045, grad_fn=<NllLoss2DBackward0>)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = criterion(outt.permute(0,2,1), lbls[\"input_ids\"])\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer\n",
    "# https://github.com/huggingface/transformers/blob/v4.48.0/src/transformers/models/bart/modeling_bart.py#L948\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You need to specify either `text` or `text_target`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m x2 \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello_input2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello_output2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      7\u001b[0m txts \u001b[38;5;241m=\u001b[39m [x1,x2]\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_pair_target\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtxts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\newma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2862\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2860\u001b[0m all_kwargs\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m   2861\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2862\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to specify either `text` or `text_target`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2863\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2864\u001b[0m     \u001b[38;5;66;03m# The context manager will send the inputs as normal texts and not text_target, but we shouldn't change the\u001b[39;00m\n\u001b[0;32m   2865\u001b[0m     \u001b[38;5;66;03m# input mode in this case.\u001b[39;00m\n\u001b[0;32m   2866\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n",
      "\u001b[1;31mValueError\u001b[0m: You need to specify either `text` or `text_target`."
     ]
    }
   ],
   "source": [
    "x1 = [\n",
    "    \"Hello_input\",\n",
    "    \"Hello_output\"]\n",
    "x2 = [\n",
    "    \"Hello_input2\",\n",
    "    \"Hello_output2\"]\n",
    "txts = [x1,x2]\n",
    "\n",
    "tokenizer(text_pair_target   = txts, return_tensors='pt',padding=True ,truncation=True)['input_ids'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer, BartModel\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "#model = BartModel.from_pretrained('facebook/bart-base')#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adapters\n",
    "\n",
    "adapters.init(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapters import AutoAdapterModel\n",
    "from adapters import SeqBnInvConfig\n",
    "\n",
    "config = SeqBnInvConfig()\n",
    "a_name = model.model.add_adapter(\"lang_adapter\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38603520"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = 0\n",
    "for p in model.lm_head.parameters():\n",
    "    print(n)\n",
    "    all += p.numel()\n",
    "\n",
    "all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapters import AutoAdapterModel\n",
    "from adapters import SeqBnInvConfig\n",
    "\n",
    "bart = AutoAdapterModel.from_pretrained('facebook/bart-base')\n",
    "config = SeqBnInvConfig()\n",
    "a_name = bart.add_adapter(\"lang_adapter\", config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model = bart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179214528"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = 0\n",
    "for n,p in model.named_parameters():\n",
    "    #print(n)\n",
    "    all += p.numel()\n",
    "\n",
    "all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2SeqLMOutput(loss=None, logits=tensor([[[34.6691,  7.4936, 14.3758,  ...,  7.0149,  7.0145,  1.5252],\n",
       "         [ 4.2044, -2.4469,  3.2881,  ..., -2.4035, -2.2326, -3.7704],\n",
       "         [-2.9161, -3.1179, 11.1878,  ..., -3.5924, -3.6006, -0.8332],\n",
       "         [-4.2730, -4.2597,  0.5211,  ..., -4.2162, -4.5878, -5.1886]]],\n",
       "       grad_fn=<AddBackward0>), past_key_values=((tensor([[[[-1.1472e-01, -5.2203e-01, -6.7271e-01,  ...,  3.4312e-01,\n",
       "            7.5881e-02, -2.4253e-02],\n",
       "          [-2.1543e-01, -5.3255e-03, -3.7538e-01,  ...,  8.3459e-02,\n",
       "           -7.7042e-02,  2.1141e-01],\n",
       "          [-3.6346e-02, -6.3400e-01, -2.9292e-01,  ...,  2.8656e-01,\n",
       "           -5.7040e-01, -4.8296e-03],\n",
       "          [ 3.2804e-01, -6.4497e-01, -3.2210e-01,  ...,  5.0830e-02,\n",
       "           -9.6804e-01,  1.3580e+00]],\n",
       "\n",
       "         [[ 4.2468e-01, -3.8993e-01, -3.1392e-01,  ...,  5.7610e-01,\n",
       "            1.7889e-01,  1.3113e+00],\n",
       "          [ 2.9420e-01, -3.9397e-01, -2.4000e-01,  ...,  5.7385e-01,\n",
       "            4.1969e-01,  1.2038e+00],\n",
       "          [-3.8756e-01, -4.6912e-01,  2.7460e-01,  ...,  3.4433e-01,\n",
       "           -3.5919e-01, -2.3672e+00],\n",
       "          [-8.9000e-01,  8.3673e-01,  1.7120e+00,  ...,  3.0819e+00,\n",
       "            6.8555e-01, -4.1549e+00]],\n",
       "\n",
       "         [[ 2.4880e-01, -7.2000e-01,  5.2539e-01,  ..., -1.4340e-01,\n",
       "           -5.0209e-01,  6.8954e-01],\n",
       "          [ 3.1715e-01, -5.8992e-01,  6.1172e-01,  ..., -1.1915e-01,\n",
       "           -5.5312e-01,  3.9599e-01],\n",
       "          [-3.6402e-01, -7.4453e-01,  2.1394e+00,  ...,  1.8300e-01,\n",
       "           -6.5383e-01,  1.0501e+00],\n",
       "          [-5.3534e-01,  2.9689e-01,  1.5643e+00,  ..., -4.7320e-01,\n",
       "           -1.7098e-01, -9.0677e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.2736e-01, -8.5515e-02, -3.7741e-01,  ..., -8.6122e-01,\n",
       "           -1.1205e+00, -1.8190e+00],\n",
       "          [ 3.3158e-02, -2.0971e-01, -3.9182e-01,  ..., -7.3325e-01,\n",
       "           -7.4243e-01, -1.6052e+00],\n",
       "          [-1.5903e-01, -1.2225e+00,  3.4865e-01,  ...,  2.1386e-01,\n",
       "            7.6879e-02,  2.1751e-01],\n",
       "          [-8.3920e-01,  2.9268e+00,  1.5905e+00,  ...,  4.4334e-01,\n",
       "           -7.7745e-01, -1.5666e+00]],\n",
       "\n",
       "         [[-1.8059e+00,  7.8414e-01, -2.6778e+00,  ...,  1.8138e+00,\n",
       "           -6.6813e-01,  2.5440e-01],\n",
       "          [-1.1289e+00, -2.7115e-01, -9.4246e-01,  ...,  6.0709e-01,\n",
       "            6.8408e-01,  1.7816e-01],\n",
       "          [-1.7777e-01,  1.0590e+00, -9.1580e-01,  ..., -2.8783e-01,\n",
       "            1.9189e+00,  3.6856e-01],\n",
       "          [ 1.1664e+00,  2.0943e-01,  3.3427e+00,  ..., -1.9640e+00,\n",
       "            8.4530e-01,  1.5605e-01]],\n",
       "\n",
       "         [[-1.8905e+00, -1.3374e+00, -2.0024e-01,  ..., -3.5146e-01,\n",
       "            3.3732e+00,  9.0604e-01],\n",
       "          [-1.1218e+00, -1.1084e+00,  1.2600e-01,  ..., -4.5153e-01,\n",
       "            2.4822e+00,  3.7718e-01],\n",
       "          [ 3.7493e+00,  4.5317e-01,  3.5669e+00,  ...,  1.9132e-01,\n",
       "            2.7574e+00, -1.7583e+00],\n",
       "          [ 9.1223e+00,  3.1940e+00,  2.6114e+00,  ...,  1.3355e+00,\n",
       "           -3.8338e-01, -6.1749e+00]]]], grad_fn=<RepeatBackward0>), tensor([[[[ 1.3970e-02,  8.5711e-03,  4.2567e-02,  ...,  2.5934e-02,\n",
       "            1.8217e-02,  3.0309e-04],\n",
       "          [-1.5002e-01,  9.4819e-02, -1.8786e-01,  ...,  1.7337e-01,\n",
       "            6.5229e-02,  1.3502e-01],\n",
       "          [ 3.3675e-01, -1.2668e-01, -3.5153e-01,  ...,  9.0330e-01,\n",
       "            3.8274e-01, -3.4239e-01],\n",
       "          [-4.8682e-01,  1.4935e-01, -1.0386e-01,  ...,  9.0722e-01,\n",
       "            7.8071e-01, -2.1373e+00]],\n",
       "\n",
       "         [[ 1.6660e-03,  2.0072e-03,  1.2753e-02,  ..., -1.7712e-02,\n",
       "           -8.7160e-03,  2.7763e-02],\n",
       "          [-2.4093e-01,  8.9940e-02, -4.6663e-02,  ..., -5.2553e-02,\n",
       "            1.1960e-01,  2.0457e-01],\n",
       "          [-1.9733e-01, -1.5761e-01, -9.8220e-02,  ...,  4.3870e-02,\n",
       "            1.9295e-01, -4.1441e-01],\n",
       "          [-6.0674e-02,  4.6652e-02,  1.0769e-01,  ..., -2.0856e-01,\n",
       "           -1.2971e-01, -9.9741e-02]],\n",
       "\n",
       "         [[ 3.7521e-02,  2.2700e-02,  1.6599e-02,  ..., -8.3040e-03,\n",
       "           -1.3863e-03,  2.6865e-02],\n",
       "          [ 8.8506e-02, -5.6085e-02, -1.2050e-01,  ...,  1.0894e-02,\n",
       "           -4.7252e-02, -8.6090e-02],\n",
       "          [-4.2150e-01,  5.3014e-01,  7.2577e-01,  ..., -3.1724e-01,\n",
       "           -8.7267e-02,  2.6850e-01],\n",
       "          [-4.9596e-01, -8.7825e-02, -1.7474e-02,  ..., -2.3076e-01,\n",
       "           -2.8476e-02,  7.2778e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.9010e-02,  2.2325e-02, -3.2058e-02,  ...,  4.8149e-02,\n",
       "           -8.2803e-02,  1.7972e-02],\n",
       "          [ 5.6085e-03, -1.8313e-01,  3.7853e-03,  ..., -2.2570e-01,\n",
       "           -9.6454e-03, -3.1415e-02],\n",
       "          [ 3.3817e-01, -2.3962e-01, -3.5483e-01,  ...,  3.4800e-02,\n",
       "            3.2311e-01,  2.5198e-01],\n",
       "          [ 8.5239e-02, -4.6371e-01,  5.7338e-01,  ..., -1.3601e-01,\n",
       "            4.0275e-01,  1.5027e-01]],\n",
       "\n",
       "         [[-1.5546e-02, -2.6822e-03, -1.2501e-03,  ...,  5.6616e-04,\n",
       "           -8.2873e-03,  4.9022e-03],\n",
       "          [-4.3582e-02,  6.4425e-02, -4.5720e-02,  ..., -1.2749e-01,\n",
       "            7.6779e-02, -3.4626e-02],\n",
       "          [-3.1719e-01, -8.5815e-03,  4.6748e-01,  ..., -1.9482e-01,\n",
       "            1.8620e-01, -1.7334e-01],\n",
       "          [ 1.0801e-01,  8.0595e-02, -2.3162e-01,  ..., -1.9490e-01,\n",
       "            5.3135e-01,  5.1622e-02]],\n",
       "\n",
       "         [[-1.0830e-01,  3.7901e-02,  7.9404e-02,  ...,  1.3109e-03,\n",
       "           -6.1677e-02, -4.4620e-02],\n",
       "          [-2.0674e-02,  2.2254e-01, -3.2515e-02,  ...,  3.4202e-02,\n",
       "            3.5936e-01,  5.9296e-03],\n",
       "          [ 1.2989e-01,  2.4600e-01,  2.9064e-01,  ...,  3.2916e-01,\n",
       "           -1.5146e-01, -2.5509e-01],\n",
       "          [ 3.0771e-02, -3.8746e-02, -2.6464e-01,  ...,  1.0887e-01,\n",
       "            2.9795e-01,  1.3353e-01]]]], grad_fn=<RepeatBackward0>), tensor([[[[-0.3413,  0.4655,  0.8543,  ..., -0.3965, -0.0911,  0.1652],\n",
       "          [-0.2817,  0.0863,  0.7803,  ..., -0.3906, -0.0937,  0.0221],\n",
       "          [-0.1865,  0.2094,  0.8432,  ..., -0.2752, -0.0724, -0.0877],\n",
       "          [-0.0698, -0.0525,  0.8068,  ..., -0.2401, -0.0460, -0.0663]],\n",
       "\n",
       "         [[-0.1318,  0.8405,  0.0333,  ..., -0.2159, -0.1427, -0.0636],\n",
       "          [-0.0921,  0.6276, -0.0459,  ..., -0.1370, -0.0043,  0.0492],\n",
       "          [-0.0434,  0.7585, -0.0086,  ..., -0.1684,  0.0070,  0.0200],\n",
       "          [-0.0879,  0.5274, -0.1175,  ..., -0.2583, -0.0316,  0.0490]],\n",
       "\n",
       "         [[-0.3175, -0.1119,  0.0169,  ..., -0.0085, -0.5134, -0.3227],\n",
       "          [-0.1482,  0.0616,  0.0199,  ..., -0.0900, -0.3957, -0.1924],\n",
       "          [-0.1515, -0.0189,  0.0125,  ..., -0.0871, -0.5204, -0.1188],\n",
       "          [-0.1312,  0.1257,  0.0284,  ..., -0.1659, -0.3741, -0.0496]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.2588,  0.5019,  0.1231,  ..., -0.1096,  0.0636, -0.2102],\n",
       "          [ 0.0851,  0.3383,  0.2688,  ..., -0.0939, -0.0698, -0.0679],\n",
       "          [ 0.0760,  0.2985,  0.2371,  ..., -0.1276,  0.0981, -0.1147],\n",
       "          [-0.0036,  0.2416,  0.3302,  ..., -0.0350,  0.0554,  0.0979]],\n",
       "\n",
       "         [[ 0.3618, -0.3667, -0.2878,  ...,  0.3101,  0.2686, -0.2122],\n",
       "          [ 0.3146, -0.3278, -0.2045,  ...,  0.1731,  0.3303, -0.0350],\n",
       "          [ 0.3224, -0.2711, -0.2182,  ...,  0.2113,  0.2795, -0.0860],\n",
       "          [ 0.2471, -0.2688, -0.1223,  ...,  0.0840,  0.3269,  0.0566]],\n",
       "\n",
       "         [[-0.2773,  0.1978, -0.8526,  ..., -0.1296, -0.1308, -0.0547],\n",
       "          [-0.3342,  0.2257, -0.6088,  ..., -0.1247, -0.1708, -0.2140],\n",
       "          [-0.2935,  0.1893, -0.6914,  ..., -0.0683, -0.0812, -0.1607],\n",
       "          [-0.2636,  0.3537, -0.3551,  ..., -0.0643, -0.1279, -0.1709]]]],\n",
       "       grad_fn=<RepeatBackward0>), tensor([[[[ 0.0009, -0.0395, -0.0460,  ...,  0.0344,  0.0314, -0.0004],\n",
       "          [ 0.0320, -0.1154,  0.0040,  ...,  0.1041, -0.0149, -0.0868],\n",
       "          [ 0.0454, -0.0946, -0.0455,  ...,  0.0491,  0.0128, -0.0575],\n",
       "          [ 0.0178, -0.1088,  0.0362,  ...,  0.1145,  0.0304, -0.0597]],\n",
       "\n",
       "         [[-0.0073,  0.0100,  0.0114,  ..., -0.0239,  0.0044, -0.0010],\n",
       "          [-0.0485,  0.0167,  0.0474,  ...,  0.0217, -0.0129, -0.0716],\n",
       "          [ 0.0163,  0.0455,  0.0034,  ..., -0.0055,  0.0935, -0.0063],\n",
       "          [-0.0904,  0.0130,  0.0571,  ..., -0.0780,  0.0797,  0.0865]],\n",
       "\n",
       "         [[-0.0221,  0.0446, -0.0293,  ..., -0.0047,  0.0269,  0.0075],\n",
       "          [ 0.0295, -0.0356, -0.0510,  ...,  0.0311, -0.0135,  0.0106],\n",
       "          [-0.0066,  0.0211, -0.1021,  ..., -0.0016, -0.0457, -0.0121],\n",
       "          [ 0.0472,  0.0051, -0.0283,  ...,  0.0436, -0.0495, -0.0528]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1590,  0.0082,  0.0224,  ...,  0.1520, -0.0336, -0.1189],\n",
       "          [-0.0570, -0.0141,  0.0261,  ...,  0.0878, -0.0294, -0.0830],\n",
       "          [-0.0909, -0.0532,  0.0392,  ...,  0.0735,  0.0573, -0.0267],\n",
       "          [-0.0333, -0.0677,  0.0307,  ...,  0.0888,  0.0794, -0.0405]],\n",
       "\n",
       "         [[-0.0099, -0.0176, -0.0127,  ...,  0.0155, -0.0545,  0.0132],\n",
       "          [ 0.0471,  0.0164,  0.0114,  ..., -0.0504, -0.0072,  0.0120],\n",
       "          [ 0.0189, -0.0589,  0.0848,  ...,  0.0135, -0.0594, -0.0238],\n",
       "          [ 0.0765, -0.0370,  0.0150,  ...,  0.0272, -0.0257, -0.0591]],\n",
       "\n",
       "         [[ 0.0494,  0.0362,  0.0089,  ...,  0.0224, -0.0020,  0.0319],\n",
       "          [ 0.1434,  0.1411,  0.1388,  ...,  0.0129, -0.0206,  0.0507],\n",
       "          [ 0.0977,  0.0736,  0.0654,  ..., -0.0222, -0.0080,  0.0933],\n",
       "          [ 0.1355,  0.1396,  0.1125,  ..., -0.0318, -0.0296,  0.0789]]]],\n",
       "       grad_fn=<RepeatBackward0>)), (tensor([[[[-2.7152e-02, -1.3585e-02,  2.9810e-02,  ...,  6.9820e-02,\n",
       "            2.0984e-02, -2.3352e-01],\n",
       "          [ 1.0565e+00,  2.6863e-01, -2.4007e-01,  ..., -4.1032e-01,\n",
       "            7.0918e-01,  6.2874e-01],\n",
       "          [ 5.3075e-01, -3.0352e-01, -7.9871e-01,  ..., -1.3809e+00,\n",
       "           -6.8548e-01,  2.3943e+00],\n",
       "          [ 1.1680e+00, -6.9559e-01, -1.0493e+00,  ..., -1.1127e+00,\n",
       "           -6.8397e-01,  1.8617e+00]],\n",
       "\n",
       "         [[ 2.3907e-01, -2.5910e-01, -2.5064e-01,  ...,  5.6009e-01,\n",
       "            6.4257e-02,  4.7884e-02],\n",
       "          [-4.1228e-01, -2.3198e-02,  4.7487e-01,  ...,  4.9453e-01,\n",
       "           -1.4346e+00,  1.0847e+00],\n",
       "          [-1.4853e+00,  4.2155e-01,  1.4645e+00,  ..., -6.8138e-02,\n",
       "           -1.3267e+00,  1.5551e-01],\n",
       "          [-2.2831e+00, -1.7434e+00,  6.4165e-01,  ...,  1.2247e-01,\n",
       "           -1.8933e-01, -4.8003e-01]],\n",
       "\n",
       "         [[ 1.7375e-01, -8.3622e-02,  8.3895e-01,  ...,  7.4816e-01,\n",
       "           -1.2611e-01,  6.2761e-02],\n",
       "          [ 2.1000e+00, -7.6357e-01,  1.4372e+00,  ..., -2.4841e+00,\n",
       "            1.0595e+00,  1.0793e+00],\n",
       "          [-9.7530e-01,  9.9279e-01, -4.6572e+00,  ..., -1.2747e+00,\n",
       "           -5.2444e-01, -3.7307e-01],\n",
       "          [-3.2663e+00,  1.2442e+00, -2.9759e+00,  ..., -2.0120e+00,\n",
       "           -7.1137e-01,  1.1953e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.1166e-01, -1.5924e-01, -6.0933e-02,  ...,  3.2214e-01,\n",
       "            2.6194e-02, -4.6266e-02],\n",
       "          [ 1.2638e+00, -6.9893e-01, -6.0849e-01,  ..., -4.2501e-01,\n",
       "            1.0537e+00, -1.3360e-01],\n",
       "          [ 2.1063e+00,  6.4232e+00, -9.7902e-01,  ..., -5.8168e-01,\n",
       "           -1.0203e-01,  1.0624e+00],\n",
       "          [ 1.8333e+00,  7.9227e+00, -1.2842e+00,  ...,  6.7996e-02,\n",
       "           -1.9109e+00, -4.6266e-01]],\n",
       "\n",
       "         [[ 6.3145e-01,  3.6612e-02,  7.4526e-03,  ..., -1.3400e-02,\n",
       "            1.3294e-01, -1.2723e-01],\n",
       "          [-1.9035e-01, -6.3417e-02, -1.6249e-01,  ...,  5.7705e-02,\n",
       "            3.8246e-01,  3.4129e-01],\n",
       "          [-1.1327e+00,  5.2233e-01, -7.1604e-01,  ..., -1.4465e+00,\n",
       "            8.1660e-01, -7.4106e-01],\n",
       "          [-1.2142e+00,  7.8292e-01, -8.1131e-02,  ..., -2.4793e+00,\n",
       "            2.7560e+00, -8.3624e-01]],\n",
       "\n",
       "         [[-2.4235e-01, -9.8601e-03,  4.3894e-02,  ..., -1.5752e-01,\n",
       "            1.3746e+00,  4.0266e-01],\n",
       "          [-1.6288e-01,  1.1052e+00,  9.6963e-02,  ..., -7.2774e-01,\n",
       "            3.9575e-01,  1.2707e-01],\n",
       "          [ 6.9966e-01, -1.9270e-01, -4.3660e-01,  ...,  2.6133e+00,\n",
       "           -2.3804e+00, -2.0947e+00],\n",
       "          [ 5.2899e-01,  3.9100e-01,  1.0872e+00,  ...,  1.2532e+00,\n",
       "           -4.3626e+00, -2.2546e+00]]]], grad_fn=<RepeatBackward0>), tensor([[[[-3.9396e-03, -2.3507e-03,  6.9081e-05,  ..., -5.7484e-03,\n",
       "           -6.1392e-04,  1.8311e-03],\n",
       "          [-1.6067e-01,  1.4082e-01,  1.0546e-01,  ..., -8.2457e-02,\n",
       "           -4.0128e-02, -5.8672e-02],\n",
       "          [ 4.4142e-01,  1.6473e+00,  3.2310e-01,  ...,  1.6402e+00,\n",
       "            1.0178e+00, -5.6459e-01],\n",
       "          [ 7.3121e-01,  6.2589e-01, -1.0724e-01,  ...,  2.1431e-01,\n",
       "           -9.8033e-01, -1.0824e-01]],\n",
       "\n",
       "         [[ 1.0908e-02,  2.7301e-02,  9.5112e-03,  ..., -2.9456e-02,\n",
       "            1.3763e-02, -5.7327e-03],\n",
       "          [ 9.6658e-01,  1.5724e+00,  5.3783e-01,  ..., -3.9650e-01,\n",
       "            3.1591e-01,  4.5083e-01],\n",
       "          [ 3.1053e-01,  3.6239e-01,  5.3702e-01,  ..., -2.6057e-01,\n",
       "            3.1105e-01, -2.1126e-01],\n",
       "          [-1.7167e-01,  3.9392e-01, -3.2509e-02,  ..., -1.0015e-01,\n",
       "           -1.4812e-01,  1.3095e-01]],\n",
       "\n",
       "         [[ 3.0117e-03, -3.3442e-03, -4.1809e-03,  ...,  8.0006e-03,\n",
       "            6.4114e-03, -4.3814e-03],\n",
       "          [-3.7333e-01,  1.2132e-01, -9.8207e-02,  ..., -1.3092e-01,\n",
       "           -1.2981e-01, -1.3832e-01],\n",
       "          [-6.7546e-01, -3.8327e-01, -1.7592e-02,  ..., -9.5656e-02,\n",
       "           -4.5165e-01, -4.8317e-01],\n",
       "          [ 3.2440e-01,  2.1976e-01,  4.4261e-01,  ...,  7.1671e-02,\n",
       "           -1.8327e-01, -1.1584e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-8.9386e-02, -1.7148e-02,  2.3781e-03,  ...,  1.3008e-02,\n",
       "           -1.1419e-02, -1.2494e-02],\n",
       "          [-5.7778e-01, -1.7708e-02,  6.2288e-02,  ..., -2.8961e-02,\n",
       "            3.7934e-02,  1.3315e-01],\n",
       "          [-3.1469e-01,  5.0647e-01,  5.8523e-01,  ...,  6.2770e-01,\n",
       "           -1.7789e-01,  1.9934e-02],\n",
       "          [-3.9039e-01, -2.1195e-01,  9.7961e-03,  ...,  2.8195e-01,\n",
       "            1.6929e-01, -1.8565e-01]],\n",
       "\n",
       "         [[-9.9285e-04,  6.9457e-03, -3.4612e-03,  ..., -3.5296e-03,\n",
       "           -2.1985e-02, -6.8992e-03],\n",
       "          [ 1.5453e-02,  2.9358e-02, -9.3959e-02,  ...,  1.5273e-02,\n",
       "           -3.1172e-01, -3.3246e-02],\n",
       "          [ 4.0332e-01, -2.2561e-02, -1.7426e-01,  ...,  2.5735e-01,\n",
       "           -1.7220e-01,  6.8333e-02],\n",
       "          [ 3.7545e-01, -5.2022e-02,  1.9862e-01,  ..., -6.6842e-02,\n",
       "           -2.0833e-01,  2.8105e-02]],\n",
       "\n",
       "         [[ 6.6287e-03,  2.0922e-03, -1.1804e-03,  ..., -4.1234e-03,\n",
       "           -4.1217e-03,  1.0173e-03],\n",
       "          [ 2.0301e-01,  3.7776e-01, -1.8157e-01,  ..., -2.4118e-01,\n",
       "           -2.5652e-01,  3.0416e-02],\n",
       "          [-3.8399e-01, -1.1399e-01, -4.1941e-01,  ..., -2.4431e-01,\n",
       "           -2.1450e-02,  2.5303e-01],\n",
       "          [-7.3613e-02, -2.3298e-01, -2.9985e-01,  ..., -2.9795e-02,\n",
       "           -5.2102e-01, -1.8506e-03]]]], grad_fn=<RepeatBackward0>), tensor([[[[-0.2596,  0.0611, -0.2052,  ...,  0.6693, -0.2521, -0.1857],\n",
       "          [-0.2822,  0.0475, -0.1398,  ...,  0.6622, -0.2483, -0.1161],\n",
       "          [-0.2568,  0.0813, -0.1847,  ...,  0.6481, -0.1775, -0.1691],\n",
       "          [-0.1827, -0.0175, -0.0916,  ...,  0.6585, -0.3143, -0.0205]],\n",
       "\n",
       "         [[-0.2702,  0.3981, -0.4541,  ...,  0.2723,  0.1458,  0.4892],\n",
       "          [-0.1634,  0.3073, -0.4454,  ...,  0.1537,  0.2074,  0.3710],\n",
       "          [-0.1189,  0.3562, -0.4509,  ...,  0.1881,  0.1596,  0.4704],\n",
       "          [-0.0178,  0.2209, -0.3456,  ...,  0.1033,  0.2317,  0.3678]],\n",
       "\n",
       "         [[ 0.0060, -0.2538, -0.3641,  ...,  0.3467, -0.0473,  0.0523],\n",
       "          [-0.0081, -0.1587, -0.1091,  ...,  0.1601, -0.1944,  0.0212],\n",
       "          [-0.0479, -0.1420, -0.1297,  ...,  0.2585, -0.1298, -0.0272],\n",
       "          [ 0.0114, -0.1643,  0.0263,  ...,  0.2072, -0.2488, -0.0049]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1034, -0.1010,  0.2183,  ..., -0.1170, -0.1300,  0.2484],\n",
       "          [ 0.0782, -0.0851,  0.1373,  ..., -0.1729, -0.0164,  0.3369],\n",
       "          [-0.0023, -0.0087,  0.1884,  ..., -0.1618, -0.1353,  0.2734],\n",
       "          [ 0.0044, -0.0494,  0.1019,  ..., -0.2302, -0.0323,  0.3064]],\n",
       "\n",
       "         [[-0.3534, -0.7234, -0.0783,  ...,  0.2682,  0.1280,  0.2271],\n",
       "          [-0.1698, -0.6381,  0.0120,  ...,  0.1828,  0.1396,  0.1044],\n",
       "          [-0.1762, -0.6606, -0.1666,  ...,  0.2393, -0.0036,  0.2000],\n",
       "          [-0.0965, -0.5997, -0.0944,  ...,  0.1512,  0.1497,  0.0944]],\n",
       "\n",
       "         [[-0.0344,  1.3554, -0.1050,  ...,  1.0501,  0.0059, -0.3246],\n",
       "          [-0.3234,  1.0190, -0.2700,  ...,  0.7737,  0.0576,  0.2352],\n",
       "          [-0.2458,  1.2581, -0.2590,  ...,  0.9512,  0.2816,  0.2783],\n",
       "          [-0.4471,  0.9506, -0.4099,  ...,  0.7708,  0.1732,  0.5171]]]],\n",
       "       grad_fn=<RepeatBackward0>), tensor([[[[ 0.0159, -0.0165,  0.0068,  ...,  0.0014, -0.0030,  0.0008],\n",
       "          [ 0.0396,  0.0890,  0.0235,  ...,  0.0227,  0.0223,  0.0979],\n",
       "          [ 0.1068,  0.0196,  0.0350,  ..., -0.0242,  0.0034, -0.0211],\n",
       "          [ 0.0454, -0.0476,  0.0802,  ..., -0.0953,  0.0249,  0.0958]],\n",
       "\n",
       "         [[-0.0534, -0.0082, -0.0178,  ...,  0.0053, -0.0321, -0.0425],\n",
       "          [-0.0387,  0.0235, -0.0480,  ...,  0.0191, -0.0274,  0.0673],\n",
       "          [-0.2596, -0.0401,  0.0214,  ...,  0.1297, -0.0784, -0.2004],\n",
       "          [-0.1735,  0.0583,  0.1994,  ...,  0.1042, -0.0941,  0.0591]],\n",
       "\n",
       "         [[-0.0004, -0.0160,  0.0326,  ...,  0.0302,  0.0019,  0.0258],\n",
       "          [-0.0605, -0.0542,  0.0545,  ...,  0.0521, -0.0090,  0.0203],\n",
       "          [ 0.0267, -0.1733,  0.1313,  ..., -0.0192, -0.0113,  0.0197],\n",
       "          [-0.0360, -0.1132,  0.0880,  ...,  0.0942,  0.0035,  0.1528]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0174, -0.0160,  0.0236,  ..., -0.0259, -0.0186,  0.0085],\n",
       "          [-0.0965, -0.0594, -0.0068,  ..., -0.0382, -0.0303,  0.0380],\n",
       "          [-0.0675, -0.0392,  0.0008,  ..., -0.0195, -0.0300, -0.0375],\n",
       "          [-0.0387, -0.0846, -0.0096,  ..., -0.0131, -0.0500, -0.0106]],\n",
       "\n",
       "         [[-0.0195,  0.0355,  0.0567,  ...,  0.0013,  0.0353,  0.0154],\n",
       "          [ 0.0221,  0.0432, -0.0280,  ..., -0.0132,  0.0464,  0.0488],\n",
       "          [-0.0228,  0.0429,  0.0788,  ...,  0.0328,  0.1194,  0.0712],\n",
       "          [-0.0039, -0.1284, -0.0785,  ..., -0.0352,  0.0329,  0.1148]],\n",
       "\n",
       "         [[-0.0662, -0.0380, -0.0194,  ...,  0.0324, -0.0081,  0.0132],\n",
       "          [-0.0502, -0.0430, -0.0659,  ...,  0.0089,  0.0276, -0.0151],\n",
       "          [-0.0324, -0.0436, -0.0335,  ...,  0.0372, -0.0131,  0.0452],\n",
       "          [-0.0549, -0.1069, -0.0077,  ...,  0.1332,  0.0831,  0.0079]]]],\n",
       "       grad_fn=<RepeatBackward0>)), (tensor([[[[-5.7784e-01, -3.3233e-01, -1.8615e-01,  ...,  1.9551e-01,\n",
       "           -7.5539e-01,  4.9387e-01],\n",
       "          [-4.6988e-01, -6.7731e-01,  9.6332e-01,  ...,  9.7590e-01,\n",
       "           -3.0779e-01,  5.8253e-01],\n",
       "          [-2.6047e+00, -2.9246e-01,  4.6254e-01,  ...,  4.2910e-01,\n",
       "            1.3529e-03,  3.6839e-01],\n",
       "          [-2.5571e+00, -1.8327e+00, -1.1660e+00,  ..., -5.5022e-01,\n",
       "            7.1112e-01,  3.4175e-01]],\n",
       "\n",
       "         [[ 1.3304e+00, -4.4514e-01, -5.1276e-01,  ..., -2.9291e-01,\n",
       "            1.2456e-01,  5.3361e-01],\n",
       "          [ 8.6799e-01, -5.2406e-01, -6.8072e-02,  ...,  8.6686e-01,\n",
       "            4.5705e-01,  1.7356e+00],\n",
       "          [-9.1757e-01,  1.9247e+00, -1.7528e+00,  ...,  7.2209e-01,\n",
       "           -1.3313e+00,  7.0840e-01],\n",
       "          [-1.1562e+00,  1.4287e+00, -2.9102e+00,  ..., -1.1698e+00,\n",
       "           -8.3514e-01,  9.9123e-01]],\n",
       "\n",
       "         [[ 3.9001e-02, -1.6616e-01,  5.2152e-01,  ..., -1.7294e-01,\n",
       "            2.2832e-02, -2.6346e-01],\n",
       "          [-2.0852e-01, -8.7657e-02,  1.2884e+00,  ...,  1.2382e+00,\n",
       "           -1.4956e+00, -9.6152e-01],\n",
       "          [ 4.5395e-01,  4.9712e-02, -5.0080e-01,  ..., -8.9444e-02,\n",
       "            2.3352e-01,  6.8427e-01],\n",
       "          [-3.1524e-02,  6.2669e-01, -1.1005e+00,  ..., -1.4578e+00,\n",
       "           -1.2584e-01,  1.0354e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.4107e-01, -1.3135e-02,  4.9680e-01,  ...,  8.0827e-01,\n",
       "           -6.8873e-01, -7.8758e-01],\n",
       "          [-5.0726e-01,  9.3038e-01, -2.0088e+00,  ..., -4.0453e-01,\n",
       "            4.2228e-01,  5.3560e-01],\n",
       "          [ 3.2951e-01,  2.8760e+00,  1.4765e+00,  ..., -3.7316e+00,\n",
       "           -9.1338e-01, -9.5563e-01],\n",
       "          [ 1.0999e+00,  1.9921e+00,  9.4517e-01,  ..., -4.4161e+00,\n",
       "           -9.5788e-01, -3.1108e-01]],\n",
       "\n",
       "         [[ 2.7001e-01, -3.4619e-01, -4.0713e-01,  ..., -1.7103e-01,\n",
       "           -3.0123e-02, -1.1740e+00],\n",
       "          [ 2.3096e-01, -2.6446e-01,  7.8207e-01,  ..., -3.4300e-01,\n",
       "            1.2618e+00, -8.0768e-01],\n",
       "          [-2.5601e+00, -8.1878e-02,  7.0209e-01,  ..., -2.6854e-02,\n",
       "           -1.0592e+00,  6.5218e+00],\n",
       "          [-1.1810e+00, -7.2695e-01,  3.4785e-01,  ..., -2.5931e-01,\n",
       "           -1.6660e+00,  8.7297e+00]],\n",
       "\n",
       "         [[ 1.1427e+00, -3.2966e-01, -9.2793e-01,  ..., -6.2095e-01,\n",
       "           -1.6110e+00,  5.6713e-01],\n",
       "          [-6.1977e-01, -8.0700e-01, -3.7799e-01,  ...,  1.4838e+00,\n",
       "           -6.5053e-01,  4.6982e-02],\n",
       "          [-1.9601e+00, -1.9301e-01,  5.4292e-01,  ...,  1.2206e+00,\n",
       "            1.4490e+00,  2.8555e-01],\n",
       "          [-4.3136e+00, -2.3104e+00,  2.2030e+00,  ..., -9.2607e-01,\n",
       "           -7.9811e-02, -4.6669e-01]]]], grad_fn=<RepeatBackward0>), tensor([[[[ 2.3117e-03,  7.8186e-03,  2.3322e-03,  ..., -4.6874e-03,\n",
       "           -2.1014e-03,  3.0420e-03],\n",
       "          [ 6.3925e-02,  7.5523e-02,  4.9303e-02,  ...,  6.4778e-03,\n",
       "           -2.5090e-02,  1.6872e-02],\n",
       "          [-4.5663e-02,  2.3280e-01, -2.9690e-01,  ...,  7.6235e-02,\n",
       "            5.1609e-01, -2.6767e-02],\n",
       "          [-3.3444e-01, -3.2438e-01, -1.6036e-01,  ...,  1.7467e-01,\n",
       "            2.3722e-01,  4.9678e-01]],\n",
       "\n",
       "         [[-1.4865e-02,  2.8406e-03,  2.0148e-03,  ...,  4.5649e-03,\n",
       "            6.8511e-03, -5.1297e-03],\n",
       "          [ 8.8059e-03,  1.3391e-02, -1.7803e-03,  ..., -2.8103e-02,\n",
       "            2.0305e-02,  1.9015e-02],\n",
       "          [-5.5726e-02, -5.2877e-01, -4.0815e-02,  ...,  9.8167e-02,\n",
       "            6.4710e-02,  1.6406e-02],\n",
       "          [ 2.3336e-02, -1.1394e-01, -7.1157e-02,  ...,  6.3104e-02,\n",
       "           -2.4525e-01, -4.7524e-01]],\n",
       "\n",
       "         [[-1.5471e-03, -2.7293e-03, -8.1852e-04,  ..., -5.8318e-03,\n",
       "           -5.5570e-03,  2.5541e-03],\n",
       "          [ 3.9457e-03,  4.9766e-02, -7.6298e-04,  ...,  1.5608e-02,\n",
       "            5.3336e-02, -1.0641e-02],\n",
       "          [ 5.4825e-01, -2.9909e-01, -1.5598e-01,  ...,  7.3117e-01,\n",
       "            2.3526e-01, -1.9982e-02],\n",
       "          [ 7.9423e-01, -1.3865e+00, -3.6606e-01,  ...,  6.9689e-01,\n",
       "           -1.2092e-02,  2.2762e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.1652e-03, -6.8058e-03,  1.1994e-02,  ...,  5.7614e-04,\n",
       "            7.6559e-03,  5.9405e-03],\n",
       "          [ 4.8896e-01, -7.2011e-01,  6.9177e-01,  ...,  2.8243e-01,\n",
       "            6.2654e-01,  1.1438e-01],\n",
       "          [-1.7303e-01, -2.0887e-01, -3.0205e-01,  ..., -5.2898e-01,\n",
       "            3.4831e-01,  9.2971e-02],\n",
       "          [-5.9608e-01, -2.7612e-01,  2.0433e-01,  ..., -4.7304e-01,\n",
       "           -2.3183e-01,  8.4464e-02]],\n",
       "\n",
       "         [[ 6.2996e-03,  7.2038e-03, -4.3437e-03,  ...,  5.8569e-03,\n",
       "            5.5284e-03,  8.6414e-03],\n",
       "          [ 1.5388e-01,  8.2864e-02,  2.7199e-03,  ...,  1.1869e-01,\n",
       "            5.8302e-03,  8.7274e-02],\n",
       "          [ 1.7088e-01,  4.9184e-01,  9.4434e-01,  ..., -1.8895e-02,\n",
       "            5.3961e-01,  2.9864e-01],\n",
       "          [ 1.1194e-01,  3.5934e-01,  1.1929e-01,  ...,  2.7055e-02,\n",
       "           -6.6907e-01,  9.8114e-01]],\n",
       "\n",
       "         [[-1.3389e-02, -1.9408e-02,  2.3837e-02,  ..., -8.0650e-03,\n",
       "            1.0639e-02, -9.3072e-04],\n",
       "          [-1.7327e-02,  1.9362e-02,  9.6760e-03,  ...,  2.6780e-02,\n",
       "           -2.3665e-02,  1.3082e-02],\n",
       "          [-6.0370e-02, -2.9657e-01,  3.6597e-01,  ...,  3.8205e-02,\n",
       "            4.6124e-02, -2.4484e-01],\n",
       "          [-5.6946e-02, -2.2884e-01, -3.7429e-01,  ..., -1.3143e-01,\n",
       "            2.9393e-01,  1.3250e-02]]]], grad_fn=<RepeatBackward0>), tensor([[[[-1.2191e-01, -3.0882e-01, -2.6147e-01,  ...,  3.1793e-01,\n",
       "           -1.8847e-01,  3.4206e-01],\n",
       "          [-3.2563e-02, -2.3612e-01, -1.4933e-01,  ...,  3.5085e-01,\n",
       "           -6.9033e-02,  3.8608e-01],\n",
       "          [-1.1539e-01, -2.6385e-01, -1.3025e-01,  ...,  2.7407e-01,\n",
       "           -3.0181e-02,  4.5497e-01],\n",
       "          [-8.2410e-02, -2.7695e-01, -1.0604e-02,  ...,  4.1363e-01,\n",
       "           -8.9247e-02,  2.4580e-01]],\n",
       "\n",
       "         [[-7.7188e-01,  5.1296e-01, -9.8182e-03,  ..., -5.4338e-02,\n",
       "           -6.3730e-02, -2.0802e-01],\n",
       "          [-5.4863e-01,  3.5407e-01, -1.9388e-02,  ..., -1.0242e-01,\n",
       "           -4.4793e-02,  6.6768e-04],\n",
       "          [-6.7311e-01,  3.1865e-01,  5.4767e-02,  ...,  7.9071e-03,\n",
       "            9.5297e-04, -1.4407e-01],\n",
       "          [-3.9632e-01,  1.7821e-01,  6.7947e-02,  ..., -1.8183e-01,\n",
       "           -3.9487e-02, -7.4946e-02]],\n",
       "\n",
       "         [[ 3.3465e-01,  3.3866e-01, -2.5761e-01,  ...,  9.4823e-01,\n",
       "            1.5136e+00,  2.0135e-01],\n",
       "          [ 2.3689e-01,  3.1153e-01, -3.6762e-01,  ...,  8.1883e-01,\n",
       "            1.2127e+00,  2.1665e-01],\n",
       "          [ 1.9427e-01,  2.7994e-01, -3.0827e-01,  ...,  9.8038e-01,\n",
       "            1.3414e+00,  9.2865e-02],\n",
       "          [ 3.1771e-01,  2.9041e-01, -1.4526e-01,  ...,  7.0352e-01,\n",
       "            1.0321e+00,  2.2582e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.0050e-01,  5.4227e-01, -1.9651e-01,  ...,  5.1863e-01,\n",
       "            1.3362e-01, -8.7232e-01],\n",
       "          [ 3.1053e-01,  5.4187e-01, -3.6941e-01,  ...,  4.0300e-01,\n",
       "            1.5140e-02, -5.6126e-01],\n",
       "          [ 2.8397e-01,  5.7748e-01, -3.2392e-01,  ...,  3.7239e-01,\n",
       "            2.0618e-02, -6.0518e-01],\n",
       "          [ 3.2022e-01,  5.9676e-01, -4.3903e-01,  ...,  2.9878e-01,\n",
       "            4.0979e-02, -3.9135e-01]],\n",
       "\n",
       "         [[ 3.5572e-01,  1.4795e-01,  2.7203e-01,  ..., -2.5567e-01,\n",
       "            6.4966e-01, -3.2435e-01],\n",
       "          [ 2.5476e-01,  2.0850e-02,  4.0946e-01,  ..., -9.8527e-02,\n",
       "            7.4012e-01, -1.9634e-01],\n",
       "          [ 2.3383e-01, -1.2720e-04,  2.7520e-01,  ..., -2.1288e-01,\n",
       "            6.5981e-01, -2.0861e-01],\n",
       "          [ 1.1515e-01, -9.6855e-02,  4.1841e-01,  ..., -9.2049e-02,\n",
       "            7.9385e-01, -1.4188e-01]],\n",
       "\n",
       "         [[-1.5897e-01,  2.2131e-01,  7.0295e-01,  ...,  3.3690e-01,\n",
       "            4.9149e-02,  3.3912e-01],\n",
       "          [-1.2307e-01,  3.3998e-01,  5.8530e-01,  ...,  2.3320e-01,\n",
       "            7.6898e-02,  5.8166e-02],\n",
       "          [-1.0426e-01,  3.1668e-01,  6.7810e-01,  ...,  1.5068e-01,\n",
       "           -2.7351e-02,  7.4087e-02],\n",
       "          [-1.4031e-01,  3.7662e-01,  5.0543e-01,  ...,  1.3673e-01,\n",
       "            1.9789e-01, -4.8342e-02]]]], grad_fn=<RepeatBackward0>), tensor([[[[-1.0940e-02, -7.3161e-03, -9.4591e-03,  ...,  2.8253e-05,\n",
       "           -1.6069e-02, -1.3050e-02],\n",
       "          [ 5.8141e-03,  5.8714e-03,  7.8352e-02,  ..., -2.2925e-02,\n",
       "           -4.7778e-02, -2.1360e-02],\n",
       "          [-1.1699e-01,  3.8598e-02,  6.1118e-02,  ...,  1.4448e-02,\n",
       "           -2.9467e-03, -1.2782e-02],\n",
       "          [-1.7068e-01,  2.7680e-02, -8.3239e-02,  ...,  7.9092e-02,\n",
       "           -2.7583e-02, -1.7180e-02]],\n",
       "\n",
       "         [[-2.9273e-03,  1.4126e-02, -2.3933e-02,  ..., -1.7863e-02,\n",
       "            1.9831e-03, -1.0811e-02],\n",
       "          [ 5.6505e-02,  1.0795e-01,  3.2826e-02,  ...,  2.5092e-02,\n",
       "            3.7394e-02,  2.3828e-02],\n",
       "          [ 4.9330e-02,  1.1293e-01,  2.3806e-02,  ..., -3.1339e-02,\n",
       "            8.4212e-02, -5.0422e-02],\n",
       "          [ 9.6235e-02,  5.2232e-02,  1.9770e-02,  ..., -5.6852e-02,\n",
       "            1.1365e-02, -1.9592e-03]],\n",
       "\n",
       "         [[-9.7913e-03, -1.6138e-02,  8.7846e-03,  ..., -1.3437e-03,\n",
       "            8.8661e-04, -1.8581e-02],\n",
       "          [ 2.6444e-02,  6.8105e-03, -4.4262e-02,  ..., -8.9107e-03,\n",
       "           -1.2998e-02, -2.8934e-02],\n",
       "          [-6.1679e-03, -4.1686e-02, -3.4189e-02,  ...,  4.1661e-03,\n",
       "           -9.6797e-03, -1.0833e-01],\n",
       "          [ 1.9929e-03, -2.4769e-02, -4.9122e-03,  ...,  2.3694e-02,\n",
       "            1.8818e-02, -7.6297e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.1884e-03, -2.0968e-02, -8.9489e-03,  ...,  2.1420e-02,\n",
       "            3.2340e-02, -1.6980e-02],\n",
       "          [-5.8926e-02, -7.3824e-02, -6.3890e-02,  ..., -3.9970e-03,\n",
       "            5.7858e-03, -2.0285e-03],\n",
       "          [ 2.4415e-02, -5.9614e-03, -1.4086e-02,  ..., -2.0411e-02,\n",
       "            5.2747e-02, -9.5942e-03],\n",
       "          [ 3.3728e-02, -1.5695e-01, -9.2683e-02,  ..., -3.7947e-02,\n",
       "            5.1423e-02, -9.8297e-02]],\n",
       "\n",
       "         [[ 2.1481e-03, -1.2015e-03, -2.3083e-02,  ..., -1.5862e-02,\n",
       "            1.7607e-02, -1.0169e-03],\n",
       "          [ 4.7972e-03, -3.1235e-02,  7.8106e-02,  ..., -6.2815e-02,\n",
       "           -2.6364e-02,  3.8713e-02],\n",
       "          [-4.9942e-02,  3.8259e-03, -2.2228e-02,  ..., -4.4480e-02,\n",
       "           -6.2464e-03,  1.7839e-02],\n",
       "          [-3.8320e-02, -1.3815e-02,  7.5931e-02,  ..., -7.8463e-02,\n",
       "           -8.6083e-03,  7.1482e-02]],\n",
       "\n",
       "         [[-9.9476e-05,  1.7734e-02, -8.4969e-04,  ...,  1.7829e-04,\n",
       "           -7.8089e-03, -5.0189e-03],\n",
       "          [ 3.5915e-03,  1.2782e-02, -1.8048e-02,  ...,  2.4394e-02,\n",
       "            1.1247e-01, -3.8051e-03],\n",
       "          [-2.4789e-02,  8.9094e-02,  3.1837e-02,  ...,  2.1641e-02,\n",
       "            5.2774e-02,  2.7504e-02],\n",
       "          [-9.6838e-02,  2.3963e-02, -2.6963e-02,  ...,  6.4235e-02,\n",
       "            1.0178e-01, -9.8729e-02]]]], grad_fn=<RepeatBackward0>)), (tensor([[[[ 3.6441e-01, -9.3076e-01,  5.7006e-01,  ..., -1.3170e+00,\n",
       "            9.3893e-01, -8.8675e-01],\n",
       "          [-9.3033e-01,  3.9461e-02, -1.5225e+00,  ..., -3.3451e-01,\n",
       "           -3.6980e-01, -9.6610e-01],\n",
       "          [-9.3358e-01, -7.4737e-01, -8.6667e-01,  ...,  5.6510e+00,\n",
       "           -3.9390e+00,  8.1562e-01],\n",
       "          [-3.0293e-01,  4.2881e-01, -1.9282e+00,  ...,  7.1664e+00,\n",
       "           -3.3045e+00, -4.6794e-01]],\n",
       "\n",
       "         [[-4.3488e-01,  1.7904e-01, -1.5318e+00,  ...,  5.6587e-01,\n",
       "           -5.7728e-02,  1.1487e+00],\n",
       "          [-1.2804e-01, -1.3348e-01,  4.4583e-02,  ...,  5.3556e-01,\n",
       "           -7.6785e-01,  8.1906e-01],\n",
       "          [-9.1952e-01,  9.0457e-02, -4.6454e-01,  ..., -1.0878e+00,\n",
       "           -3.2189e-02,  1.4076e+00],\n",
       "          [-1.0980e-01,  1.6008e-01, -1.1557e+00,  ..., -1.9685e+00,\n",
       "            6.0696e-01,  1.3608e+00]],\n",
       "\n",
       "         [[-1.1169e+00, -6.6878e-01,  9.4834e-01,  ...,  1.6474e-01,\n",
       "           -3.2717e-01, -6.4514e-01],\n",
       "          [-7.1259e-02, -4.1836e-01, -1.0040e+00,  ..., -1.5478e+00,\n",
       "            8.2244e-01,  6.5467e-02],\n",
       "          [ 3.5269e-01,  1.3601e+00,  1.3121e+00,  ...,  2.8340e+00,\n",
       "            1.6079e+00, -8.8350e-01],\n",
       "          [-1.0048e-02,  9.1538e-01,  5.9419e-01,  ...,  1.9738e+00,\n",
       "            2.9927e+00,  1.1920e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0374e+00, -6.0918e-01,  1.5834e+00,  ..., -1.7860e+00,\n",
       "            6.7044e-01,  1.4576e-01],\n",
       "          [-1.9894e-01, -8.5392e-01, -1.2801e-01,  ..., -8.5024e-01,\n",
       "           -1.6433e-01,  6.0665e-01],\n",
       "          [ 1.3222e+00, -1.6661e+00,  5.8543e-01,  ...,  3.4297e-01,\n",
       "           -5.6163e-01, -1.5745e+00],\n",
       "          [-7.7787e-01, -1.3803e+00,  7.4775e-01,  ...,  3.2055e-01,\n",
       "           -4.5867e-01, -2.9949e+00]],\n",
       "\n",
       "         [[ 4.1891e-01,  6.0911e-01,  1.8072e-01,  ..., -2.2936e-01,\n",
       "            5.9874e-02, -8.0676e-01],\n",
       "          [ 8.4223e-01,  3.4732e-01,  2.4195e+00,  ..., -1.5776e+00,\n",
       "            2.7227e+00,  9.0126e-01],\n",
       "          [-7.2789e-02,  1.5227e+00,  3.2688e-01,  ...,  6.4443e-02,\n",
       "           -2.1617e+00,  6.2746e+00],\n",
       "          [-6.5265e-02,  1.1890e+00,  3.4101e-01,  ..., -4.8615e-01,\n",
       "           -2.5394e+00,  7.7719e+00]],\n",
       "\n",
       "         [[-5.3800e-01,  7.6329e-02, -1.6945e+00,  ..., -4.0459e-01,\n",
       "            1.3542e+00,  1.3045e-01],\n",
       "          [ 3.9007e-01, -1.0476e+00, -2.9904e-01,  ...,  6.2503e-01,\n",
       "           -6.4011e-01,  1.0729e+00],\n",
       "          [-7.5381e-01,  1.8995e+00,  9.5773e+00,  ..., -1.1278e+00,\n",
       "           -1.0595e+00,  6.6112e-02],\n",
       "          [-1.0015e+00,  1.9899e+00,  1.0936e+01,  ...,  7.9534e-01,\n",
       "           -1.5587e+00, -1.6962e-01]]]], grad_fn=<RepeatBackward0>), tensor([[[[ 1.3881e-02, -4.9322e-04, -1.1246e-02,  ..., -2.4651e-03,\n",
       "            2.5251e-02,  3.6106e-02],\n",
       "          [ 3.6491e-01, -1.0791e-01,  3.5960e-02,  ..., -2.1656e-01,\n",
       "            3.0139e-01,  8.0409e-01],\n",
       "          [ 9.2372e-02,  5.2607e-02,  2.3291e-01,  ..., -1.3407e-01,\n",
       "           -1.3829e-01, -2.4824e-01],\n",
       "          [-1.1290e-01,  4.2292e-02,  2.8459e-02,  ...,  2.2680e-01,\n",
       "           -5.8344e-02,  1.0629e-01]],\n",
       "\n",
       "         [[ 4.0024e-03, -4.9805e-03, -3.6067e-03,  ..., -3.9441e-03,\n",
       "           -2.5083e-03, -6.2236e-03],\n",
       "          [ 2.1701e-01, -5.4694e-01, -2.4600e-01,  ..., -3.7240e-01,\n",
       "            4.3704e-02, -3.5823e-01],\n",
       "          [-4.8919e-01, -1.2498e-01, -2.1189e-01,  ...,  2.4755e-01,\n",
       "           -2.3791e-02,  2.3424e-02],\n",
       "          [ 1.1577e-01,  3.0745e-01, -6.5518e-02,  ..., -1.1356e-01,\n",
       "           -1.7904e-01,  1.0435e-02]],\n",
       "\n",
       "         [[-5.4422e-04,  1.6412e-03,  4.8362e-05,  ...,  6.0397e-03,\n",
       "            5.2082e-04,  5.4455e-03],\n",
       "          [-1.8245e-01,  4.3479e-01,  2.2667e-01,  ...,  2.5292e-01,\n",
       "           -1.1235e-01,  2.6162e-02],\n",
       "          [ 3.4557e-01,  3.3120e-01,  4.4646e-01,  ...,  3.1861e-01,\n",
       "           -1.3299e-01,  4.5440e-01],\n",
       "          [ 4.2233e-02, -6.8951e-02,  2.2028e-01,  ..., -5.4322e-01,\n",
       "            2.9523e-01,  7.6580e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.3151e-02, -8.8265e-04,  8.4362e-03,  ..., -8.9072e-03,\n",
       "            5.6234e-04, -6.1061e-03],\n",
       "          [-9.1138e-01,  1.3855e-01,  7.1370e-01,  ..., -6.1131e-01,\n",
       "           -3.6413e-01, -2.3917e-01],\n",
       "          [-2.0559e-01,  2.2235e-01,  5.6989e-01,  ...,  1.7179e-01,\n",
       "           -4.9148e-01,  3.0345e-01],\n",
       "          [ 2.5722e-01,  5.2963e-01, -1.1766e-01,  ..., -2.1665e-01,\n",
       "           -3.8443e-01, -1.8653e-01]],\n",
       "\n",
       "         [[ 6.3886e-03,  1.8554e-03,  4.0965e-03,  ...,  5.4373e-03,\n",
       "            3.0361e-03,  3.7255e-02],\n",
       "          [-1.5917e-01,  1.2985e+00,  2.4091e-02,  ..., -5.6701e-01,\n",
       "           -3.0754e-01,  9.8552e-01],\n",
       "          [ 1.0238e-01,  3.1191e-02,  3.7928e-01,  ...,  4.5678e-01,\n",
       "            2.1468e-01, -7.0740e-01],\n",
       "          [-5.3169e-01, -1.0340e-01,  3.9591e-01,  ...,  5.0801e-01,\n",
       "           -5.3345e-02, -5.2297e-01]],\n",
       "\n",
       "         [[-6.9216e-03,  9.7916e-04, -1.8743e-03,  ...,  5.7280e-03,\n",
       "           -7.2031e-03, -5.9723e-04],\n",
       "          [-6.8049e-01, -3.7438e-01, -1.8987e-01,  ...,  1.7778e-01,\n",
       "           -3.8375e-01, -7.0069e-01],\n",
       "          [-4.7857e-01,  1.7331e-01,  3.3278e-01,  ..., -4.0853e-01,\n",
       "           -6.6638e-01,  2.3056e-02],\n",
       "          [ 6.8008e-02, -2.6148e-01, -4.2986e-01,  ...,  7.4017e-01,\n",
       "            2.8326e-01, -2.6492e-01]]]], grad_fn=<RepeatBackward0>), tensor([[[[ 0.5256,  0.2992,  0.2901,  ..., -0.2124, -0.4201,  0.4025],\n",
       "          [ 0.3329,  0.0296,  0.3124,  ..., -0.1003, -0.4081,  0.4475],\n",
       "          [ 0.5993,  0.1017,  0.3912,  ..., -0.1333, -0.3481,  0.4062],\n",
       "          [ 0.3334, -0.0164,  0.3567,  ...,  0.0081, -0.3694,  0.3518]],\n",
       "\n",
       "         [[ 0.1816,  0.1241,  0.7505,  ..., -0.3111, -0.0769,  0.2571],\n",
       "          [ 0.1586,  0.1922,  0.4119,  ..., -0.1599, -0.0961,  0.0553],\n",
       "          [ 0.2349,  0.2160,  0.5136,  ..., -0.2303, -0.1636,  0.0852],\n",
       "          [ 0.1853,  0.1849,  0.2873,  ..., -0.1534, -0.1219, -0.0343]],\n",
       "\n",
       "         [[ 0.2028,  0.1345, -0.3778,  ..., -0.6193,  1.0672,  0.2385],\n",
       "          [ 0.0167,  0.1853, -0.2051,  ..., -0.5484,  1.0138,  0.2278],\n",
       "          [ 0.0905,  0.2378, -0.3090,  ..., -0.5438,  1.0116,  0.2622],\n",
       "          [-0.0018,  0.2508, -0.1730,  ..., -0.6342,  1.0046,  0.2438]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.2814, -0.0582,  0.0960,  ...,  0.5858,  0.2756,  0.4786],\n",
       "          [ 0.1486, -0.1036,  0.1054,  ...,  0.4306,  0.1876,  0.3755],\n",
       "          [ 0.0615, -0.1427, -0.0072,  ...,  0.3069,  0.0397,  0.2710],\n",
       "          [ 0.2272,  0.0024,  0.0568,  ...,  0.4117,  0.3544,  0.3108]],\n",
       "\n",
       "         [[ 0.1909, -0.0536,  0.3018,  ..., -0.5845,  0.2911, -0.3902],\n",
       "          [ 0.2795, -0.1552,  0.0391,  ..., -0.5491,  0.3356, -0.4240],\n",
       "          [ 0.2093, -0.1655,  0.1801,  ..., -0.5622,  0.2888, -0.3495],\n",
       "          [ 0.2807, -0.1364, -0.0356,  ..., -0.6367,  0.3301, -0.4360]],\n",
       "\n",
       "         [[ 0.0908,  0.2115, -0.2084,  ..., -0.4365, -0.0610, -0.2609],\n",
       "          [ 0.1449,  0.0370, -0.0881,  ..., -0.3504, -0.2980,  0.0814],\n",
       "          [ 0.0563,  0.0928, -0.1556,  ..., -0.4038, -0.2716, -0.1382],\n",
       "          [ 0.1952, -0.0117, -0.1573,  ..., -0.2952, -0.3894,  0.0876]]]],\n",
       "       grad_fn=<RepeatBackward0>), tensor([[[[ 0.0017, -0.0150, -0.0394,  ...,  0.0253, -0.0312,  0.0115],\n",
       "          [ 0.0913, -0.0725, -0.0795,  ...,  0.0469, -0.0327,  0.0293],\n",
       "          [ 0.0996, -0.0099,  0.0283,  ...,  0.0536, -0.0078,  0.0068],\n",
       "          [ 0.1284, -0.0253, -0.0683,  ...,  0.0721, -0.0467,  0.0675]],\n",
       "\n",
       "         [[ 0.0059,  0.0064, -0.0042,  ...,  0.0174,  0.1107, -0.0083],\n",
       "          [ 0.0096, -0.0193,  0.0092,  ...,  0.0102,  0.2992, -0.0885],\n",
       "          [ 0.0099, -0.0332,  0.0521,  ..., -0.0159,  0.4106, -0.0836],\n",
       "          [ 0.0257,  0.0043, -0.0583,  ...,  0.0144,  0.3805, -0.0863]],\n",
       "\n",
       "         [[-0.0009,  0.0116, -0.0112,  ...,  0.0116, -0.0862, -0.0039],\n",
       "          [-0.0111,  0.0105, -0.0203,  ...,  0.0181, -0.1097, -0.0105],\n",
       "          [ 0.0161, -0.0037, -0.1029,  ...,  0.0353, -0.2920, -0.0064],\n",
       "          [ 0.0229,  0.0131, -0.1379,  ...,  0.0656, -0.2365,  0.0949]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0012, -0.0329,  0.0005,  ...,  0.0260, -0.0157,  0.0026],\n",
       "          [ 0.0243, -0.0785,  0.1217,  ...,  0.0858,  0.0190, -0.0515],\n",
       "          [-0.0580, -0.0496, -0.0202,  ...,  0.1180, -0.0486, -0.0288],\n",
       "          [ 0.1241,  0.0051,  0.0839,  ...,  0.0543,  0.0136, -0.0221]],\n",
       "\n",
       "         [[ 0.0042, -0.0041,  0.0206,  ..., -0.0079,  0.0316,  0.0590],\n",
       "          [ 0.0191, -0.0116,  0.0202,  ...,  0.0055,  0.0043,  0.0350],\n",
       "          [ 0.0115,  0.0280,  0.0406,  ..., -0.0128,  0.0066,  0.0554],\n",
       "          [ 0.0228, -0.0688, -0.0013,  ...,  0.0206, -0.0125, -0.0078]],\n",
       "\n",
       "         [[-0.0105, -0.0022, -0.0127,  ...,  0.0243, -0.0140, -0.0196],\n",
       "          [-0.0509, -0.0569, -0.0038,  ...,  0.0043,  0.0381,  0.0076],\n",
       "          [-0.0602, -0.0540, -0.0076,  ..., -0.0187,  0.0131, -0.0341],\n",
       "          [-0.0623,  0.0348, -0.0608,  ..., -0.0827,  0.0757, -0.0259]]]],\n",
       "       grad_fn=<RepeatBackward0>)), (tensor([[[[-8.1029e-01,  6.9687e-01, -2.1338e-01,  ..., -3.0414e-01,\n",
       "            1.5698e-01, -4.7558e-01],\n",
       "          [ 1.6484e+00, -1.3724e+00,  2.4173e-01,  ...,  1.2446e+00,\n",
       "           -1.7022e+00, -5.5214e-01],\n",
       "          [ 5.6438e+00, -5.6076e+00,  9.8600e-01,  ...,  2.8717e+00,\n",
       "           -5.6086e+00, -2.4203e+00],\n",
       "          [ 5.5718e+00, -3.6615e+00,  7.9940e-03,  ...,  3.6923e+00,\n",
       "           -5.7028e+00, -2.5002e+00]],\n",
       "\n",
       "         [[ 5.3611e-01,  1.1804e+00,  8.8763e-02,  ..., -1.5557e+00,\n",
       "           -3.4764e-01, -6.2147e-01],\n",
       "          [ 9.5992e-01, -7.0010e-01, -1.0737e+00,  ...,  9.6386e-01,\n",
       "            1.9913e+00,  5.4134e-01],\n",
       "          [-4.8582e-01, -5.0431e-01, -2.1320e+00,  ..., -1.1804e+00,\n",
       "           -2.1171e+00,  2.3015e+00],\n",
       "          [-6.8217e-01,  3.1830e-01, -9.7198e-01,  ..., -1.0977e+00,\n",
       "           -2.1931e+00,  2.3473e+00]],\n",
       "\n",
       "         [[ 8.2000e-01, -3.8878e-01,  1.3725e-01,  ..., -4.4143e-01,\n",
       "           -1.2663e+00,  3.6739e-01],\n",
       "          [-8.9361e-01, -1.6878e+00,  4.8509e-01,  ...,  1.2857e+00,\n",
       "            2.1388e+00,  3.7145e-01],\n",
       "          [-3.3191e-01, -2.7777e+00,  8.0409e-01,  ..., -4.8722e-01,\n",
       "           -1.1209e+00, -7.5125e-03],\n",
       "          [-1.8514e-01, -9.3747e-01, -6.1330e-01,  ...,  3.1822e-01,\n",
       "           -1.8197e+00,  6.4388e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-8.1713e-01, -1.5081e+00,  3.4536e-01,  ...,  2.9683e-01,\n",
       "           -6.2011e-01,  4.3083e-01],\n",
       "          [ 1.9623e-01, -3.0418e-01, -5.7590e-01,  ..., -2.3439e-01,\n",
       "           -6.6577e-01, -7.8625e-01],\n",
       "          [-7.0385e-01,  2.0549e+00, -3.9209e+00,  ..., -7.7737e+00,\n",
       "            1.9611e+00, -5.3058e-01],\n",
       "          [-8.0431e-01,  5.9134e-01, -4.1872e+00,  ..., -7.5281e+00,\n",
       "            1.0868e+00, -4.7945e-01]],\n",
       "\n",
       "         [[-8.1037e-02,  1.1075e+00, -2.1000e-01,  ...,  1.0037e+00,\n",
       "            2.7332e-01, -1.3104e-01],\n",
       "          [-3.5145e-01,  9.0612e-01, -1.6782e+00,  ...,  5.2663e-01,\n",
       "           -7.3884e-01,  2.2751e+00],\n",
       "          [-1.7216e-01, -5.3757e-01, -2.7556e+00,  ...,  2.0903e+00,\n",
       "            1.3159e+00,  2.0293e+00],\n",
       "          [ 4.0779e-01, -1.5051e+00, -4.6393e+00,  ...,  1.8138e+00,\n",
       "            3.7491e-01, -1.0594e+00]],\n",
       "\n",
       "         [[-7.5763e-02, -6.4444e-01,  9.5272e-01,  ..., -1.4228e+00,\n",
       "           -6.8960e-01,  3.8580e-01],\n",
       "          [ 1.6518e+00, -4.5445e-01, -6.4542e-01,  ...,  1.6018e+00,\n",
       "            7.1230e-02,  5.8811e-01],\n",
       "          [-1.0608e+00, -1.1760e+00,  2.0325e+00,  ...,  2.1279e+00,\n",
       "           -1.0346e+00, -9.0773e-02],\n",
       "          [-7.5435e-01, -5.7500e-02,  1.3411e+00,  ...,  1.1279e+00,\n",
       "           -2.5326e-01,  8.6333e-01]]]], grad_fn=<RepeatBackward0>), tensor([[[[-3.3102e-02,  5.8075e-03,  1.5726e-03,  ..., -1.4559e-02,\n",
       "            2.1908e-02, -1.2756e-02],\n",
       "          [ 3.7503e-01,  1.8617e-01,  2.8948e-02,  ..., -1.8246e-01,\n",
       "           -1.7348e-02, -7.6298e-01],\n",
       "          [ 7.1839e-02, -3.5952e-01,  5.4333e-01,  ..., -1.6059e-01,\n",
       "           -1.0142e+00, -5.2912e-01],\n",
       "          [-2.2833e-01,  2.3741e-01,  6.2614e-01,  ..., -6.4433e-02,\n",
       "           -1.3118e-01, -3.6422e-01]],\n",
       "\n",
       "         [[-9.5553e-03,  3.4029e-03,  2.0994e-03,  ...,  1.7287e-02,\n",
       "           -6.0017e-03, -2.8989e-03],\n",
       "          [ 3.7893e-02,  5.9724e-02,  2.5629e-01,  ...,  5.7866e-01,\n",
       "            9.0351e-02, -7.5564e-02],\n",
       "          [ 1.9457e-01, -2.3147e-01, -5.6793e-02,  ...,  2.8267e-01,\n",
       "           -4.1256e-02,  2.1402e-01],\n",
       "          [-7.8926e-02,  3.3896e-01, -4.4581e-01,  ...,  4.9815e-01,\n",
       "           -2.0999e-01,  2.0940e-01]],\n",
       "\n",
       "         [[-1.3445e-02,  1.1129e-02, -3.3002e-03,  ..., -9.9537e-03,\n",
       "           -1.2411e-02,  2.9608e-02],\n",
       "          [-9.9543e-01,  6.6336e-01, -5.4740e-01,  ..., -9.7805e-01,\n",
       "           -5.2687e-01,  2.0255e+00],\n",
       "          [ 6.4532e-02, -4.7090e-01,  1.9032e-01,  ...,  1.0715e-01,\n",
       "            3.0402e-01,  2.3047e-02],\n",
       "          [ 1.2522e-01,  3.0397e-02,  5.0959e-01,  ...,  7.9693e-02,\n",
       "            5.7469e-01, -3.0558e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.5480e-03, -8.5214e-03, -1.0066e-02,  ..., -1.4398e-02,\n",
       "           -1.2302e-02, -1.0169e-02],\n",
       "          [-8.8474e-02,  1.4465e-01,  2.2698e-01,  ..., -4.4968e-01,\n",
       "            9.3922e-02, -1.5899e-01],\n",
       "          [ 8.1455e-02,  5.5341e-02,  4.8003e-03,  ...,  1.0508e-01,\n",
       "            2.4829e-01,  4.1710e-01],\n",
       "          [-1.0310e-01,  1.2082e-01, -3.7078e-02,  ..., -1.5318e-01,\n",
       "            2.5066e-01,  2.6147e-01]],\n",
       "\n",
       "         [[-1.1640e-03, -3.0473e-03, -4.7543e-03,  ..., -4.4980e-03,\n",
       "           -3.9097e-03,  1.3986e-03],\n",
       "          [-3.1498e-01, -4.3294e-01,  8.0784e-03,  ..., -1.6433e-01,\n",
       "           -6.4881e-01,  4.3396e-01],\n",
       "          [ 1.5194e-01, -1.1451e-02, -2.7182e-01,  ..., -9.6594e-02,\n",
       "            1.5087e-01,  1.9492e-01],\n",
       "          [ 5.0234e-01,  3.5843e-01, -1.9868e-01,  ..., -4.4716e-01,\n",
       "           -3.4705e-01,  1.5330e-02]],\n",
       "\n",
       "         [[-4.0750e-03,  9.6517e-03,  3.6180e-02,  ...,  1.7060e-03,\n",
       "            3.2949e-03,  2.3848e-03],\n",
       "          [-5.0167e-01,  4.9003e-01,  3.6520e-01,  ...,  1.3259e-01,\n",
       "            1.2343e-01, -1.8028e-01],\n",
       "          [-1.8769e-01, -5.6259e-01, -3.7768e-02,  ..., -4.3900e-01,\n",
       "           -1.2723e-01,  9.0866e-02],\n",
       "          [ 1.5817e-01, -4.2516e-01,  3.8203e-02,  ..., -5.1568e-01,\n",
       "           -5.1807e-01,  5.8360e-01]]]], grad_fn=<RepeatBackward0>), tensor([[[[ 0.3143, -0.2234,  0.1843,  ...,  0.1184, -0.2642,  0.3116],\n",
       "          [ 0.0793, -0.1053,  0.1816,  ...,  0.1289, -0.2791,  0.2865],\n",
       "          [ 0.3136, -0.1076,  0.0999,  ...,  0.0798, -0.3079,  0.2778],\n",
       "          [ 0.0477, -0.0722,  0.2705,  ...,  0.0643, -0.3064,  0.2655]],\n",
       "\n",
       "         [[-0.3954,  0.3762,  0.5087,  ...,  0.0392, -0.4052, -1.0176],\n",
       "          [-0.2194,  0.2747,  0.2552,  ..., -0.2474, -0.3269, -0.8123],\n",
       "          [-0.3159,  0.2069,  0.2087,  ..., -0.1854, -0.1318, -0.8421],\n",
       "          [-0.2413,  0.1512,  0.0392,  ..., -0.3740, -0.2485, -0.6692]],\n",
       "\n",
       "         [[-0.0312, -0.0512,  0.8766,  ..., -0.0224,  0.0807, -0.1087],\n",
       "          [ 0.1032, -0.0223,  0.6474,  ...,  0.1095,  0.0276, -0.0330],\n",
       "          [ 0.0545,  0.0082,  0.7715,  ...,  0.1086, -0.0286, -0.0367],\n",
       "          [ 0.2296,  0.0428,  0.5644,  ...,  0.1792, -0.0458, -0.0363]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.8281,  0.1407,  0.0014,  ..., -0.5829, -0.0294,  0.2797],\n",
       "          [-0.6129,  0.0463,  0.0602,  ..., -0.6140,  0.2663,  0.2765],\n",
       "          [-0.6330,  0.0376,  0.1286,  ..., -0.5262,  0.1574,  0.2003],\n",
       "          [-0.6646,  0.1487,  0.1274,  ..., -0.4397,  0.3699,  0.1240]],\n",
       "\n",
       "         [[-0.0509, -0.2597, -0.6682,  ..., -0.3358, -0.0174,  0.4478],\n",
       "          [-0.1221, -0.3450, -0.4807,  ..., -0.3184, -0.0484,  0.3119],\n",
       "          [-0.0360, -0.2394, -0.6905,  ..., -0.1344,  0.0251,  0.4907],\n",
       "          [-0.1899, -0.3950, -0.2789,  ..., -0.2650, -0.0932,  0.1633]],\n",
       "\n",
       "         [[ 0.4801,  0.4257,  0.7638,  ...,  0.3738, -0.1974,  0.3426],\n",
       "          [ 0.4179,  0.3573,  0.5830,  ...,  0.2965, -0.1018,  0.2697],\n",
       "          [ 0.3132,  0.3211,  0.6427,  ...,  0.3746, -0.0802,  0.3367],\n",
       "          [ 0.3353,  0.2728,  0.5499,  ...,  0.1993, -0.0794,  0.2455]]]],\n",
       "       grad_fn=<RepeatBackward0>), tensor([[[[ 0.0170, -0.0352, -0.0253,  ..., -0.0116, -0.0067,  0.0025],\n",
       "          [-0.0021, -0.0889, -0.0030,  ...,  0.0250, -0.0018,  0.0234],\n",
       "          [-0.0163, -0.0914, -0.0428,  ..., -0.0110, -0.0142, -0.0064],\n",
       "          [ 0.0953, -0.0979, -0.0300,  ...,  0.0427,  0.0032,  0.0935]],\n",
       "\n",
       "         [[ 0.0088,  0.0083, -0.0110,  ...,  0.0054,  0.0026,  0.0086],\n",
       "          [-0.0201,  0.0342, -0.0052,  ...,  0.0215, -0.0343,  0.0924],\n",
       "          [ 0.0164,  0.0238,  0.0110,  ...,  0.0503,  0.0053,  0.0066],\n",
       "          [ 0.0464,  0.0733,  0.0432,  ...,  0.0543,  0.0006,  0.0567]],\n",
       "\n",
       "         [[-0.0023,  0.0081,  0.0049,  ...,  0.0292,  0.0037, -0.0017],\n",
       "          [-0.0715,  0.0787, -0.0244,  ...,  0.0845,  0.0240, -0.0429],\n",
       "          [-0.0685, -0.0044, -0.0319,  ...,  0.0633, -0.0137, -0.0280],\n",
       "          [-0.0960, -0.0527, -0.0200,  ...,  0.0837,  0.0485,  0.0022]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0144, -0.0072,  0.0030,  ..., -0.0035,  0.0033, -0.0060],\n",
       "          [ 0.0638, -0.0004,  0.0509,  ..., -0.0006, -0.0316, -0.0602],\n",
       "          [ 0.0323, -0.0286, -0.0225,  ...,  0.0490, -0.1110, -0.0701],\n",
       "          [ 0.1054,  0.0197,  0.0223,  ...,  0.0039,  0.0291, -0.0494]],\n",
       "\n",
       "         [[ 0.0005, -0.0147, -0.0077,  ..., -0.0388,  0.0684, -0.0122],\n",
       "          [-0.0221, -0.0727, -0.0716,  ..., -0.0622,  0.0604,  0.0182],\n",
       "          [-0.0124, -0.1080, -0.0794,  ..., -0.0008,  0.0172,  0.0003],\n",
       "          [ 0.0878, -0.0216, -0.0004,  ..., -0.0591,  0.0447, -0.0080]],\n",
       "\n",
       "         [[-0.0102, -0.0155,  0.0030,  ..., -0.0207, -0.0196, -0.0033],\n",
       "          [ 0.0171, -0.0680, -0.0029,  ..., -0.0774, -0.0121,  0.0251],\n",
       "          [-0.0201, -0.0333, -0.0251,  ..., -0.1571, -0.0034, -0.0383],\n",
       "          [ 0.0083, -0.0859, -0.0331,  ..., -0.1624, -0.0064, -0.0504]]]],\n",
       "       grad_fn=<RepeatBackward0>)), (tensor([[[[-1.0080, -0.7526,  0.5323,  ...,  0.4695,  1.0541,  1.0491],\n",
       "          [ 0.3144,  0.2816, -1.5723,  ...,  2.1197,  0.8852, -0.0967],\n",
       "          [ 0.1501,  1.0397,  0.0543,  ...,  1.8220, -0.7288,  2.4583],\n",
       "          [ 1.6880, -0.2329,  0.1942,  ...,  1.6403, -0.6107,  0.7809]],\n",
       "\n",
       "         [[-0.1127,  0.3759,  0.0709,  ...,  1.1780, -0.6255,  0.1725],\n",
       "          [ 0.3845, -0.7816,  0.7322,  ..., -0.8534,  0.0724,  0.7965],\n",
       "          [ 0.7035, -2.2412,  0.5984,  ..., -4.1891, -3.0413,  0.8143],\n",
       "          [ 0.4977, -2.3859,  1.6649,  ..., -4.6333, -1.6278,  0.4111]],\n",
       "\n",
       "         [[ 0.8575, -0.4648,  0.6772,  ..., -0.0657,  0.1146,  0.0079],\n",
       "          [-0.4066, -1.4911, -0.8015,  ..., -0.5736,  0.0121,  0.9343],\n",
       "          [-3.3396, -0.4669, -3.9476,  ...,  0.7005,  1.8646,  1.1497],\n",
       "          [-3.4763, -0.6292, -3.2764,  ...,  0.8955,  1.5262,  0.7326]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.6533,  0.8264,  0.0134,  ...,  0.4221, -0.3016,  0.0506],\n",
       "          [-0.3405,  0.0665, -0.0931,  ..., -0.5736,  0.3278,  1.5114],\n",
       "          [-0.5094,  0.1076,  0.6700,  ..., -1.9630,  4.3021,  3.0907],\n",
       "          [-2.2577, -0.8686, -0.6987,  ..., -2.3067,  4.1779,  2.4913]],\n",
       "\n",
       "         [[-0.0499, -1.7596, -0.5739,  ...,  0.6156,  0.2818,  0.2949],\n",
       "          [-0.5343,  0.6494,  0.5570,  ...,  0.3128,  1.5429,  0.3577],\n",
       "          [-1.0228,  1.8974,  0.6110,  ..., -1.4794,  1.8235, -0.0064],\n",
       "          [-0.5567,  2.1731,  0.5661,  ..., -1.0774,  0.1275,  0.5890]],\n",
       "\n",
       "         [[ 0.6066,  0.3155,  0.6340,  ...,  0.1856,  0.0470, -0.0983],\n",
       "          [-0.0988, -1.6713, -1.6003,  ..., -0.5253, -1.0221,  1.2019],\n",
       "          [-1.3433,  0.3874,  0.4389,  ..., -1.6179,  1.7694,  0.4613],\n",
       "          [-2.2571,  1.2619, -0.7587,  ..., -2.1233,  0.4761, -0.1904]]]],\n",
       "       grad_fn=<RepeatBackward0>), tensor([[[[-2.4454e-03,  5.6835e-05, -3.2014e-03,  ..., -8.3468e-04,\n",
       "            6.8327e-04,  6.0999e-04],\n",
       "          [-1.7125e-01, -7.7261e-02,  7.4746e-02,  ..., -2.1882e-01,\n",
       "           -7.7036e-02, -5.9957e-02],\n",
       "          [-3.7404e-01, -4.4211e-01, -2.5483e-01,  ...,  2.6676e-02,\n",
       "            7.2255e-02, -4.0081e-01],\n",
       "          [ 6.3557e-02, -2.3568e-02, -3.7203e-01,  ...,  5.0267e-02,\n",
       "            2.0563e-01, -5.5715e-01]],\n",
       "\n",
       "         [[ 1.0845e-02,  2.5268e-03, -6.6390e-03,  ...,  3.8501e-04,\n",
       "           -9.2840e-04, -2.5070e-03],\n",
       "          [-2.2642e-01,  4.1831e-01, -3.4782e-01,  ...,  1.0919e-01,\n",
       "            2.5601e-01, -2.0238e-01],\n",
       "          [-3.2873e-01,  1.4936e-01, -4.4540e-01,  ...,  3.7296e-01,\n",
       "           -1.9841e-01, -5.3666e-03],\n",
       "          [-1.6726e-02, -7.7264e-01,  1.3884e-01,  ...,  1.3138e-01,\n",
       "           -4.5857e-01, -8.3384e-02]],\n",
       "\n",
       "         [[ 1.0362e-02, -3.4869e-03,  3.2146e-04,  ...,  1.0068e-02,\n",
       "           -3.1446e-03, -1.3481e-03],\n",
       "          [ 1.9971e-01, -1.5822e-01,  1.8812e-01,  ...,  1.7465e-01,\n",
       "           -1.1615e-01, -4.7290e-02],\n",
       "          [ 2.0547e-01,  9.7546e-04,  1.3645e-01,  ...,  3.7049e-01,\n",
       "           -1.9054e-02, -7.1157e-02],\n",
       "          [ 5.7228e-01, -2.4564e-01, -1.1349e-02,  ...,  1.0550e-01,\n",
       "            1.2313e-01,  4.8145e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.8866e-03,  2.7571e-03, -5.0941e-03,  ..., -2.1714e-02,\n",
       "           -6.3520e-03, -3.8882e-03],\n",
       "          [-8.9492e-02,  1.0859e-01, -3.1949e-02,  ..., -1.5373e-01,\n",
       "           -1.3672e-01, -1.7458e-01],\n",
       "          [ 5.6437e-01, -1.5709e-01, -1.1474e-01,  ..., -4.4568e-01,\n",
       "           -4.1622e-01, -1.1964e-02],\n",
       "          [ 3.2862e-01, -2.8678e-01, -2.9387e-01,  ..., -2.8831e-01,\n",
       "           -5.0643e-02, -5.9352e-02]],\n",
       "\n",
       "         [[ 2.6266e-03,  6.8307e-03,  9.7956e-04,  ..., -5.0093e-04,\n",
       "           -3.1941e-03,  4.6494e-03],\n",
       "          [ 2.9217e-02,  1.7713e-01, -2.3771e-01,  ..., -9.6327e-03,\n",
       "            1.4843e-02,  1.3070e-01],\n",
       "          [-1.0067e-01, -2.5061e-01, -4.2080e-02,  ...,  2.2593e-01,\n",
       "           -5.3740e-02, -3.1262e-01],\n",
       "          [-1.3503e-01, -2.4118e-01,  2.7893e-02,  ...,  3.1416e-01,\n",
       "            2.4421e-01, -4.5728e-01]],\n",
       "\n",
       "         [[-8.5606e-04,  2.7553e-03,  3.1233e-03,  ...,  2.8545e-03,\n",
       "            1.6644e-03, -5.3508e-04],\n",
       "          [ 1.6757e-01,  6.1643e-02,  2.2697e-01,  ...,  3.2822e-01,\n",
       "            2.3724e-01, -1.0713e-01],\n",
       "          [-1.4340e-01, -6.6547e-01,  1.9623e-01,  ...,  1.4805e-01,\n",
       "            2.6146e-02,  2.0423e-01],\n",
       "          [ 3.0564e-01, -3.3238e-01,  3.4185e-02,  ..., -9.7753e-01,\n",
       "           -1.4441e-02,  2.2304e-01]]]], grad_fn=<RepeatBackward0>), tensor([[[[-0.2354, -0.3889, -0.1653,  ...,  0.7552, -0.2259, -0.3323],\n",
       "          [-0.2854, -0.2175,  0.1455,  ...,  0.7215, -0.3516, -0.0929],\n",
       "          [-0.1666, -0.3487,  0.0454,  ...,  0.3937, -0.3957, -0.0852],\n",
       "          [-0.2608, -0.1548,  0.2348,  ...,  0.3874, -0.4195,  0.0625]],\n",
       "\n",
       "         [[-0.0516,  0.2043,  0.0610,  ..., -0.1424,  0.3307,  0.2298],\n",
       "          [ 0.0947,  0.2626, -0.2001,  ...,  0.0219,  0.4046,  0.2941],\n",
       "          [ 0.1248,  0.2558, -0.0682,  ...,  0.0329,  0.4153,  0.2550],\n",
       "          [ 0.0327,  0.2765, -0.1489,  ..., -0.0888,  0.3300,  0.5158]],\n",
       "\n",
       "         [[ 1.1313,  0.2218,  0.4264,  ..., -0.7150,  0.5491,  0.6764],\n",
       "          [ 1.0407, -0.0326,  0.4217,  ..., -0.7650,  0.3963,  0.6829],\n",
       "          [ 1.0856,  0.1518,  0.4708,  ..., -0.6399,  0.4938,  0.6678],\n",
       "          [ 0.9667, -0.0867,  0.2290,  ..., -0.5137,  0.3696,  0.6484]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0576,  0.5506,  0.1790,  ...,  0.3901,  0.4016,  0.0054],\n",
       "          [-0.0323,  0.4924,  0.0572,  ...,  0.2839,  0.1437,  0.0739],\n",
       "          [-0.1186,  0.5879,  0.1573,  ...,  0.2885,  0.2035,  0.0541],\n",
       "          [-0.1384,  0.2626,  0.0935,  ...,  0.1526,  0.0714,  0.0942]],\n",
       "\n",
       "         [[-0.9474,  0.5970,  0.0029,  ..., -0.5721, -0.5011,  0.2813],\n",
       "          [-1.0828,  0.6631, -0.2562,  ..., -0.6101, -0.1825,  0.7317],\n",
       "          [-0.9639,  0.6247, -0.2636,  ..., -0.4533, -0.3871,  0.4956],\n",
       "          [-1.0095,  0.4825, -0.4931,  ..., -0.6264, -0.1285,  0.6793]],\n",
       "\n",
       "         [[ 0.2154,  0.1237,  0.0505,  ..., -0.3926,  0.2094,  1.0658],\n",
       "          [ 0.1467,  0.2224,  0.0703,  ..., -0.0419,  0.2082,  0.8072],\n",
       "          [ 0.1577,  0.0949,  0.2126,  ..., -0.2473,  0.1259,  0.8063],\n",
       "          [ 0.2241,  0.0978, -0.0318,  ..., -0.0287,  0.2189,  0.6156]]]],\n",
       "       grad_fn=<RepeatBackward0>), tensor([[[[-0.0021,  0.0009,  0.0220,  ...,  0.0037, -0.0086,  0.0024],\n",
       "          [-0.0056,  0.0268,  0.0818,  ...,  0.0618, -0.0787, -0.0665],\n",
       "          [-0.0161,  0.0278,  0.1928,  ...,  0.0166, -0.0701,  0.0333],\n",
       "          [-0.0397, -0.0008,  0.3245,  ...,  0.0198, -0.0581, -0.0143]],\n",
       "\n",
       "         [[-0.0086, -0.0067, -0.0059,  ..., -0.0040,  0.0034, -0.0065],\n",
       "          [-0.0025,  0.0550,  0.0567,  ..., -0.0108, -0.0711, -0.0220],\n",
       "          [-0.0438,  0.0379, -0.0099,  ..., -0.0128, -0.0034, -0.0475],\n",
       "          [ 0.0251,  0.0176,  0.0633,  ..., -0.0207, -0.0293, -0.0561]],\n",
       "\n",
       "         [[-0.0025,  0.0059,  0.0051,  ..., -0.0058, -0.0153,  0.0008],\n",
       "          [-0.0604,  0.0286,  0.0127,  ..., -0.0494, -0.0049,  0.0089],\n",
       "          [-0.0013,  0.0455,  0.0290,  ...,  0.0457, -0.0661,  0.0099],\n",
       "          [-0.0592, -0.0039, -0.0326,  ...,  0.0719, -0.0413,  0.0477]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0153, -0.0113, -0.0021,  ...,  0.0005, -0.0038,  0.0133],\n",
       "          [ 0.0099, -0.0304, -0.0091,  ...,  0.0423,  0.0045,  0.0366],\n",
       "          [-0.0277,  0.0054, -0.0300,  ...,  0.0218,  0.0018,  0.0945],\n",
       "          [ 0.1688, -0.0869, -0.0567,  ...,  0.0362,  0.0556,  0.0637]],\n",
       "\n",
       "         [[-0.0049,  0.0032,  0.0095,  ...,  0.0128, -0.0061, -0.0038],\n",
       "          [-0.0216,  0.0735,  0.0053,  ...,  0.0095, -0.0108, -0.0424],\n",
       "          [-0.0209,  0.0415,  0.0382,  ...,  0.0355,  0.0013, -0.0304],\n",
       "          [ 0.0413,  0.0588, -0.0377,  ...,  0.0517,  0.0464, -0.0543]],\n",
       "\n",
       "         [[ 0.0132, -0.0110,  0.0195,  ..., -0.0160,  0.0158,  0.0110],\n",
       "          [-0.0300, -0.0081,  0.0407,  ..., -0.0855, -0.0057, -0.0495],\n",
       "          [-0.0047, -0.0290,  0.0264,  ..., -0.0518,  0.0303, -0.0521],\n",
       "          [ 0.0139, -0.0422,  0.0786,  ..., -0.0820,  0.0234, -0.0333]]]],\n",
       "       grad_fn=<RepeatBackward0>))), decoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=tensor([[[-0.0408,  0.0186, -0.0034,  ...,  0.0255, -0.0044,  0.0038],\n",
       "         [-0.0996,  0.0397,  0.0275,  ...,  0.0517, -0.0250,  0.0048],\n",
       "         [-0.0938,  0.0464, -0.0068,  ...,  0.0245,  0.0040,  0.0335],\n",
       "         [-0.1085,  0.0517, -0.0363,  ...,  0.0742, -0.0308,  0.0090]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), encoder_hidden_states=None, encoder_attentions=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = [1,2,3,4]\n",
    "a = torch.tensor(a).unsqueeze(0)\n",
    "model(a,a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
