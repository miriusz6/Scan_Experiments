Data processing:
1. Reading from txt and parsing:
    reading all data at once
    special tokens: [PAD], [SOS], [EOS], no need for [UNK] since we are using a fixed vocabulary
    the same vocab for both source and target
    tokenizing by splitting in words
    trimming and padding length (unified len)
    converting to indices
    if k-fold then k equal parts based on indexes


2.
    First try with 10k steps - very lowscores
    Second try: k-fold to find optimal epoch numbers
    K-fold analisis points to faulty training/model architecture: SLIDE: K-fold + tensorboard(E3_2) to show hesitance
    



Folds slide:
variance doesnt play an importantrole over around 20 - 30  epoch